import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesClassifier
import joblib
import os
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

def load_extra_trees_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å Extra Trees"""
    model_path = "./extra_trees_20_species_model_20250724_110036.pkl"
    if os.path.exists(model_path):
        model = joblib.load(model_path)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
        return model
    else:
        print(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
        return None

def load_data_and_preprocess():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è 20 –≤–∏–¥–æ–≤"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ø–æ—Ä—è–¥–æ–∫, —á—Ç–æ –∏ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Å–∫—Ä–∏–ø—Ç–µ
    tree_types = [
        '–±–µ—Ä–µ–∑–∞', '–¥—É–±', '–µ–ª—å', '–µ–ª—å_–≥–æ–ª—É–±–∞—è', '–∏–≤–∞', '–∫–∞—à—Ç–∞–Ω', '–∫–ª–µ–Ω', 
        '–∫–ª–µ–Ω_–∞–º', '–ª–∏–ø–∞', '–ª–∏—Å—Ç–≤–µ–Ω–Ω–∏—Ü–∞', '–æ—Ä–µ—Ö', '–æ—Å–∏–Ω–∞', '—Ä—è–±–∏–Ω–∞', 
        '—Å–∏—Ä–µ–Ω—å', '—Å–æ—Å–Ω–∞', '—Ç–æ–ø–æ–ª—å_–±–∞–ª—å–∑–∞–º–∏—á–µ—Å–∫–∏–π', '—Ç–æ–ø–æ–ª—å_—á–µ—Ä–Ω—ã–π', 
        '—Ç—É—è', '—á–µ—Ä–µ–º—É—Ö–∞', '—è—Å–µ–Ω—å'
    ]
    
    all_data = []
    all_labels = []
    
    print("üåø –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è 20 –≤–∏–¥–æ–≤...")
    
    spring_folder = "../–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 20 –≤–∏–¥–æ–≤"
    
    for tree_type in tree_types:
        folder_path = os.path.join(spring_folder, tree_type)
        if os.path.exists(folder_path):
            excel_files = glob.glob(os.path.join(folder_path, "*.xlsx"))
            
            for file_path in excel_files:
                try:
                    df = pd.read_excel(file_path, header=None)
                    spectrum = df.iloc[:, 1].values  # –í—Ç–æ—Ä–∞—è –∫–æ–ª–æ–Ω–∫–∞ - —Å–ø–µ–∫—Ç—Ä
                    spectrum = spectrum[~pd.isna(spectrum)]  # –£–±–∏—Ä–∞–µ–º NaN
                    
                    if len(spectrum) > 0:
                        all_data.append(spectrum)
                        all_labels.append(tree_type)
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}")
    
    if len(all_data) == 0:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return None, None, None
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_data)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ–∫—Ç—Ä–æ–≤
    X = preprocess_spectra(all_data)
    y = np.array(all_labels)
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X_features = extract_enhanced_features(X)
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
    X_train, X_test, y_train, y_test = train_test_split(
        X_features, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_test_scaled, y_test, label_encoder.classes_

def preprocess_spectra(spectra_list):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ–∫—Ç—Ä–æ–≤"""
    # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
    min_length = min(len(spectrum) for spectrum in spectra_list)
    print(f"   üìè –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ø–µ–∫—Ç—Ä–∞: {min_length}")
    
    # –û–±—Ä–µ–∑–∞–µ–º –≤—Å–µ —Å–ø–µ–∫—Ç—Ä—ã –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
    processed_spectra = []
    for spectrum in spectra_list:
        truncated = spectrum[:min_length]
        processed_spectra.append(truncated)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array
    X = np.array(processed_spectra)
    print(f"   üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
    
    return X

def extract_enhanced_features(X):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Å–ø–µ–∫—Ç—Ä–æ–≤"""
    print("‚öôÔ∏è –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –†–ê–°–®–ò–†–ï–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í...")
    
    features_list = []
    
    for spectrum in X:
        features = []
        
        # –ë–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        features.extend([
            np.mean(spectrum),
            np.std(spectrum),
            np.median(spectrum),
            np.min(spectrum),
            np.max(spectrum),
            np.ptp(spectrum),  # peak-to-peak
            np.var(spectrum)
        ])
        
        # –ö–≤–∞–Ω—Ç–∏–ª–∏
        quantiles = np.percentile(spectrum, [10, 25, 75, 90])
        features.extend(quantiles)
        
        # –ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        features.extend([
            np.sum(spectrum),
            np.sum(spectrum**2),
            np.sum(spectrum**3),
            np.sum(spectrum**4)
        ])
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if len(spectrum) > 1:
            diff1 = np.diff(spectrum)
            diff2 = np.diff(diff1) if len(diff1) > 1 else [0]
            
            features.extend([
                np.mean(diff1),
                np.std(diff1),
                np.mean(diff2) if len(diff2) > 0 else 0,
                np.std(diff2) if len(diff2) > 0 else 0
            ])
        else:
            features.extend([0, 0, 0, 0])
        
        # –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if len(spectrum) > 10:
            # –†–∞–∑–¥–µ–ª—è–µ–º —Å–ø–µ–∫—Ç—Ä –Ω–∞ —á–∞—Å—Ç–∏
            n_parts = 5
            part_size = len(spectrum) // n_parts
            
            for i in range(n_parts):
                start_idx = i * part_size
                end_idx = start_idx + part_size if i < n_parts - 1 else len(spectrum)
                part = spectrum[start_idx:end_idx]
                
                features.extend([
                    np.mean(part),
                    np.std(part),
                    np.max(part),
                    np.min(part)
                ])
        else:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ —Å–ø–µ–∫—Ç—Ä —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
            features.extend([0] * (5 * 4))
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features.extend([
            np.sum(spectrum > np.mean(spectrum)),  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
            np.sum(spectrum < np.mean(spectrum)),  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
            len(spectrum),  # –¥–ª–∏–Ω–∞ —Å–ø–µ–∫—Ç—Ä–∞
            np.argmax(spectrum),  # –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º—É–º–∞
            np.argmin(spectrum),  # –∏–Ω–¥–µ–∫—Å –º–∏–Ω–∏–º—É–º–∞
        ])
        
        features_list.append(features)
    
    return np.array(features_list)

def analyze_detailed_probabilities(model, X_test, y_test, tree_types, target_species=['–æ—Å–∏–Ω–∞', '—Å–∏—Ä–µ–Ω—å'], noise_level=0.1):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ü–µ–ª–µ–≤—ã—Ö –≤–∏–¥–æ–≤"""
    
    print(f"\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –í–ï–†–û–Ø–¢–ù–û–°–¢–ï–ô –ü–†–ò {noise_level*100}% –®–£–ú–ê")
    print("="*70)
    
    for target_species_name in target_species:
        print(f"\nüìä –ê–ù–ê–õ–ò–ó –î–õ–Ø –í–ò–î–ê: {target_species_name.upper()}")
        print("-" * 50)
        
        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å —Ü–µ–ª–µ–≤–æ–≥–æ –≤–∏–¥–∞
        target_idx = np.where(tree_types == target_species_name)[0]
        if len(target_idx) == 0:
            print(f"‚ùå –í–∏–¥ {target_species_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–ø–∏—Å–∫–µ")
            continue
        
        target_idx = target_idx[0]
        
        # –ù–∞—Ö–æ–¥–∏–º –æ–±—Ä–∞–∑—Ü—ã —Ü–µ–ª–µ–≤–æ–≥–æ –≤–∏–¥–∞
        target_samples_mask = (y_test == target_idx)
        target_samples = X_test[target_samples_mask]
        
        if len(target_samples) == 0:
            print(f"‚ùå –ù–µ—Ç –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –≤–∏–¥–∞ {target_species_name}")
            continue
        
        print(f"üìà –ù–∞–π–¥–µ–Ω–æ {len(target_samples)} –æ–±—Ä–∞–∑—Ü–æ–≤ {target_species_name}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —à—É–º
        noise = np.random.normal(0, noise_level, target_samples.shape).astype(np.float32)
        target_samples_noisy = target_samples + noise
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
        probabilities = model.predict_proba(target_samples_noisy)
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å
        prob_df = pd.DataFrame(probabilities, columns=tree_types)
        prob_df.insert(0, '–û–±—Ä–∞–∑–µ—Ü', range(1, len(prob_df) + 1))
        
        print(f"\nüìã –î–ï–¢–ê–õ–¨–ù–´–ï –í–ï–†–û–Ø–¢–ù–û–°–¢–ò –î–õ–Ø {target_species_name.upper()}:")
        print("="*70)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –æ–±—Ä–∞–∑—Ü–æ–≤
        print(prob_df.head(10).to_string(index=False, float_format='%.4f'))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        mean_probs = prob_df.iloc[:, 1:].mean()
        
        print(f"\nüìä –°–†–ï–î–ù–ò–ï –í–ï–†–û–Ø–¢–ù–û–°–¢–ò –î–õ–Ø {target_species_name.upper()}:")
        print("-" * 50)
        for species, prob in mean_probs.items():
            print(f"{species:15}: {prob:.4f}")
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (1 –¥–ª—è –º–∞–∫—Å–∏–º—É–º–∞, 0 –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö)
        max_prob_matrix = np.zeros_like(probabilities)
        max_indices = np.argmax(probabilities, axis=1)
        max_prob_matrix[np.arange(len(probabilities)), max_indices] = 1
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        max_prob_df = pd.DataFrame(max_prob_matrix, columns=tree_types)
        max_prob_df.insert(0, '–û–±—Ä–∞–∑–µ—Ü', range(1, len(max_prob_df) + 1))
        
        print(f"\nüéØ –ú–ê–¢–†–ò–¶–ê –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–• –í–ï–†–û–Ø–¢–ù–û–°–¢–ï–ô (1/0) –î–õ–Ø {target_species_name.upper()}:")
        print("="*70)
        print(max_prob_df.to_string(index=False))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        mean_max_probs = max_prob_df.iloc[:, 1:].mean()
        
        print(f"\nüìà –°–†–ï–î–ù–ò–ï –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–• –í–ï–†–û–Ø–¢–ù–û–°–¢–ï–ô –î–õ–Ø {target_species_name.upper()}:")
        print("-" * 50)
        for species, prob in mean_max_probs.items():
            if prob > 0:
                print(f"{species:15}: {prob:.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
        output_filename = f"–¥–µ—Ç–∞–ª—å–Ω—ã–µ_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏_{target_species_name}_10–ø—Ä–æ—Ü.csv"
        prob_df.to_csv(output_filename, index=False, float_format='%.4f')
        print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_filename}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Ç—Ä–∏—Ü—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        max_output_filename = f"–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏_{target_species_name}_10–ø—Ä–æ—Ü.csv"
        max_prob_df.to_csv(max_output_filename, index=False)
        print(f"üíæ –ú–∞—Ç—Ä–∏—Ü–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {max_output_filename}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–ø–ª–æ–≤—É—é –∫–∞—Ä—Ç—É
        plt.figure(figsize=(16, 8))
        
        # –ü–æ–¥–≥—Ä–∞—Ñ–∏–∫ 1: –î–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        plt.subplot(1, 2, 1)
        sns.heatmap(prob_df.iloc[:, 1:].T, 
                   cmap='Blues', 
                   cbar_kws={'label': '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'},
                   xticklabels=range(1, len(prob_df) + 1),
                   yticklabels=tree_types)
        plt.title(f'–î–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ - {target_species_name} (10% —à—É–º)')
        plt.xlabel('–ù–æ–º–µ—Ä –æ–±—Ä–∞–∑—Ü–∞')
        plt.ylabel('–í–∏–¥ –¥–µ—Ä–µ–≤–∞')
        
        # –ü–æ–¥–≥—Ä–∞—Ñ–∏–∫ 2: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        plt.subplot(1, 2, 2)
        sns.heatmap(max_prob_df.iloc[:, 1:].T, 
                   cmap='Reds', 
                   cbar_kws={'label': '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'},
                   xticklabels=range(1, len(max_prob_df) + 1),
                   yticklabels=tree_types)
        plt.title(f'–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ - {target_species_name} (10% —à—É–º)')
        plt.xlabel('–ù–æ–º–µ—Ä –æ–±—Ä–∞–∑—Ü–∞')
        plt.ylabel('–í–∏–¥ –¥–µ—Ä–µ–≤–∞')
        
        plt.tight_layout()
        plt.savefig(f'—Ç–µ–ø–ª–æ–≤–∞—è_–∫–∞—Ä—Ç–∞_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π_{target_species_name}_10–ø—Ä–æ—Ü.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"\nüìä –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: —Ç–µ–ø–ª–æ–≤–∞—è_–∫–∞—Ä—Ç–∞_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π_{target_species_name}_10–ø—Ä–æ—Ü.png")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üî¨ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –í–ï–†–û–Ø–¢–ù–û–°–¢–ï–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
    print("="*70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = load_extra_trees_model()
    if model is None:
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X_test, y_test, tree_types = load_data_and_preprocess()
    if X_test is None:
        return
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏ –ø—Ä–∏ 10% —à—É–º–µ
    analyze_detailed_probabilities(model, X_test, y_test, tree_types, 
                                 target_species=['–æ—Å–∏–Ω–∞', '—Å–∏—Ä–µ–Ω—å'], 
                                 noise_level=0.1)
    
    print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")

if __name__ == "__main__":
    import glob
    main() 