import os
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings
warnings.filterwarnings('ignore')

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ TensorFlow
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    TF_AVAILABLE = True
    print("TensorFlow –¥–æ—Å—Ç—É–ø–µ–Ω!")
except ImportError:
    print("‚ö†Ô∏è TensorFlow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é.")
    TF_AVAILABLE = False
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ PyTorch –∏–ª–∏ –¥—Ä—É–≥–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
    try:
        import torch
        import torch.nn as nn
        import torch.optim as optim
        PYTORCH_AVAILABLE = True
        print("PyTorch –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏!")
    except ImportError:
        PYTORCH_AVAILABLE = False
        print("‚ö†Ô∏è PyTorch —Ç–∞–∫–∂–µ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–º—É–ª—è—Ü–∏—é.")

def load_spectral_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è 1D-AlexNet"""
    tree_types = ['–±–µ—Ä–µ–∑–∞', '–¥—É–±', '–µ–ª—å', '–∫–ª–µ–Ω', '–ª–∏–ø–∞', '–æ—Å–∏–Ω–∞', '—Å–æ—Å–Ω–∞']
    all_spectra = []
    all_labels = []
    
    print("üåø –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
    print("="*60)
    
    for tree_type in tree_types:
        folder_path = os.path.join('.', tree_type)
        if os.path.exists(folder_path):
            excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))
            print(f"üìÅ {tree_type}: {len(excel_files)} —Ñ–∞–π–ª–æ–≤")
            
            for file_path in excel_files:
                try:
                    df = pd.read_excel(file_path)
                    
                    if df.shape[1] >= 2:
                        # –ë–µ—Ä–µ–º —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–≤—Ç–æ—Ä–æ–π —Å—Ç–æ–ª–±–µ—Ü)
                        spectrum = df.iloc[:, 1].values
                        
                        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç NaN
                        spectrum = spectrum[~np.isnan(spectrum)]
                        
                        if len(spectrum) >= 100:  # –ú–∏–Ω–∏–º—É–º –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                            all_spectra.append(spectrum)
                            all_labels.append(tree_type)
                            
                except Exception as e:
                    print(f"‚ùóÔ∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
                    continue
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_spectra)} —Å–ø–µ–∫—Ç—Ä–æ–≤ —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    return all_spectra, all_labels, tree_types

def preprocess_spectra_for_1d_alexnet(spectra, labels, target_length=300):
    """
    –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–µ–∫—Ç—Ä—ã –¥–ª—è 1D-AlexNet —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏.
    """
    print("\nüîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ–∫—Ç—Ä–æ–≤ –¥–ª—è 1D-AlexNet (—É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥)...")
    print(f"üìè –¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ —Å–ø–µ–∫—Ç—Ä–∞: {target_length} (—Å –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π)")
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ —Å–ø–µ–∫—Ç—Ä—ã –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω–µ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é
    processed_spectra = []
    for spectrum in spectra:
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ø–µ–∫—Ç—Ä—ã
        if len(spectrum) < 50:
            continue
            
        # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º, –µ—Å–ª–∏ –¥–ª–∏–Ω–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
        if len(spectrum) != target_length:
            processed_spectrum = np.interp(
                np.linspace(0, len(spectrum) - 1, target_length),
                np.arange(len(spectrum)),
                spectrum
            )
        else:
            processed_spectrum = spectrum
            
        processed_spectra.append(processed_spectrum)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤
    X = np.array(processed_spectra, dtype=np.float32)
    
    # –ö–æ–¥–∏—Ä—É–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(labels)
    
    print(f"üìä –§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
    print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(np.unique(y))}")
    print(f"üè∑Ô∏è –ö–ª–∞—Å—Å—ã: {label_encoder.classes_}")
    
    return X, y, label_encoder, target_length

def create_1d_alexnet_tensorflow(input_shape, num_classes):
    """–°–æ–∑–¥–∞–µ—Ç 1D-AlexNet –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≤ TensorFlow —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞—Ç—å–µ"""
    model = keras.Sequential([
        # –ü–µ—Ä–≤—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        layers.Conv1D(filters=96, kernel_size=11, strides=4, activation='relu', 
                     input_shape=input_shape, padding='same'),
        layers.MaxPooling1D(pool_size=3, strides=2),
        layers.BatchNormalization(),
        
        # –í—Ç–æ—Ä–æ–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        layers.Conv1D(filters=256, kernel_size=5, activation='relu', padding='same'),
        layers.MaxPooling1D(pool_size=3, strides=2),
        layers.BatchNormalization(),
        
        # –¢—Ä–µ—Ç–∏–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        layers.Conv1D(filters=384, kernel_size=3, activation='relu', padding='same'),
        
        # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        layers.Conv1D(filters=384, kernel_size=3, activation='relu', padding='same'),
        
        # –ü—è—Ç—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        layers.Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),
        layers.MaxPooling1D(pool_size=3, strides=2),
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        layers.Flatten(),
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(4096, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    
    return model

def simulate_1d_alexnet_training(X_train, y_train, X_test, y_test, num_classes):
    """–°–∏–º—É–ª—è—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è 1D-AlexNet –±–µ–∑ TensorFlow"""
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.neural_network import MLPClassifier
    
    print("ü§ñ –°–∏–º—É–ª—è—Ü–∏—è 1D-AlexNet —á–µ—Ä–µ–∑ –≥–ª—É–±–æ–∫—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)...")
    
    # –°–æ–∑–¥–∞–µ–º –≥–ª—É–±–æ–∫—É—é —Å–µ—Ç—å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    model = MLPClassifier(
        hidden_layer_sizes=(1024, 512, 256, 128), # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        activation='relu',
        solver='adam',
        max_iter=500, # –£–º–µ–Ω—å—à–µ–Ω–æ, —Ç.–∫. –µ—Å—Ç—å —Ä–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
        random_state=42,
        early_stopping=True,
        n_iter_no_change=20, # –ü–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        validation_fraction=0.1,
        learning_rate_init=0.0001, # –£–º–µ–Ω—å—à–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        batch_size=32 # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    )
    
    print("üìö –û–±—É—á–µ–Ω–∏–µ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π 1D-AlexNet...")
    model.fit(X_train, y_train)
    
    # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    train_accuracy = model.score(X_train, y_train)
    test_accuracy = model.score(X_test, y_test)
    
    print(f"üìà –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ: {train_accuracy:.4f}")
    print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {test_accuracy:.4f}")
    
    return model

def test_with_gaussian_noise_1000_realizations(model, X_test, y_test, tree_types, noise_levels):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–º —à—É–º–æ–º - 1000 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ"""
    print("\n" + "="*70)
    print("üé≤ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –° –ì–ê–£–°–°–û–í–°–ö–ò–ú –®–£–ú–û–ú (1000 –†–ï–ê–õ–ò–ó–ê–¶–ò–ô)")
    print("="*70)
    
    n_realizations = 1000  # –ö–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ
    results = {}
    
    for noise_level in noise_levels:
        print(f"\nüîä –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞: {noise_level * 100:.1f}%")
        print("-" * 50)
        
        accuracies = []
        all_predictions = []
        all_true_labels = []
        
        # 1000 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π —à—É–º–∞
        for realization in range(n_realizations):
            if realization % 100 == 0:
                print(f"  –†–µ–∞–ª–∏–∑–∞—Ü–∏—è {realization + 1}/1000...")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º —Å –Ω—É–ª–µ–≤—ã–º —Å—Ä–µ–¥–Ω–∏–º
            if noise_level > 0:
                noise = np.random.normal(0, noise_level, X_test.shape).astype(np.float32)
                X_test_noisy = X_test + noise
            else:
                X_test_noisy = X_test
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            y_pred = model.predict(X_test_noisy)
            accuracy = accuracy_score(y_test, y_pred)
            accuracies.append(accuracy)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø–µ—Ä–≤–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
            if realization == 0:
                all_predictions = y_pred
                all_true_labels = y_test
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        mean_accuracy = np.mean(accuracies)
        std_accuracy = np.std(accuracies)
        
        print(f"üìä –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {mean_accuracy:.4f} ¬± {std_accuracy:.4f}")
        
        # –û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è –ø–µ—Ä–≤–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        print(f"\nüìã –û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (—à—É–º {noise_level * 100:.1f}%):")
        print(classification_report(all_true_labels, all_predictions, 
                                  target_names=tree_types, digits=3))
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = confusion_matrix(all_true_labels, all_predictions)
        print("\nüìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
        print(cm)
        
        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
        print(f"\n‚úÖ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
        class_accuracies = cm.diagonal() / cm.sum(axis=1)
        for i, tree in enumerate(tree_types):
            print(f"  {tree}: {class_accuracies[i]:.3f}")
        
        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ª–æ–∂–Ω–æ–π —Ç—Ä–µ–≤–æ–≥–∏ (False Positive Rate) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        print(f"\nüö® –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ª–æ–∂–Ω–æ–π —Ç—Ä–µ–≤–æ–≥–∏ (FPR) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:")
        for i, tree in enumerate(tree_types):
            FP = cm.sum(axis=0)[i] - cm[i, i]  # –õ–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
            TN = cm.sum() - cm.sum(axis=0)[i] - cm.sum(axis=1)[i] + cm[i, i]  # –ò—Å—Ç–∏–Ω–Ω—ã–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ
            FPR = FP / (FP + TN) if (FP + TN) != 0 else 0
            print(f"  {tree}: {FPR:.3f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results[noise_level] = {
            'mean_accuracy': mean_accuracy,
            'std_accuracy': std_accuracy,
            'class_accuracies': class_accuracies,
            'confusion_matrix': cm,
            'all_accuracies': accuracies
        }
    
    return results

def plot_noise_analysis(results, tree_types):
    """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ —à—É–º—É"""
    noise_levels = list(results.keys())
    mean_accuracies = [results[noise]['mean_accuracy'] for noise in noise_levels]
    std_accuracies = [results[noise]['std_accuracy'] for noise in noise_levels]
    
    # –ì—Ä–∞—Ñ–∏–∫ –æ–±—â–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
    plt.figure(figsize=(15, 10))
    
    plt.subplot(2, 2, 1)
    plt.errorbar([n*100 for n in noise_levels], mean_accuracies, yerr=std_accuracies, 
                marker='o', capsize=5, capthick=2, linewidth=2)
    plt.xlabel('–£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ (%)')
    plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')
    plt.title('–£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å 1D-AlexNet –∫ –≥–∞—É—Å—Å–æ–≤—Å–∫–æ–º—É —à—É–º—É')
    plt.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
    plt.subplot(2, 2, 2)
    for i, tree in enumerate(tree_types):
        class_accs = [results[noise]['class_accuracies'][i] for noise in noise_levels]
        plt.plot([n*100 for n in noise_levels], class_accs, marker='o', label=tree)
    plt.xlabel('–£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ (%)')
    plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å–∞–º')
    plt.title('–¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –≤–∏–¥–∞–º —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Ç–æ—á–Ω–æ—Å—Ç–µ–π –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —à—É–º–∞
    plt.subplot(2, 2, 3)
    max_noise = max(noise_levels)
    accuracies = results[max_noise]['all_accuracies']
    plt.hist(accuracies, bins=50, alpha=0.7, edgecolor='black')
    plt.xlabel('–¢–æ—á–Ω–æ—Å—Ç—å')
    plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
    plt.title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ (—à—É–º {max_noise*100}%)')
    plt.grid(True, alpha=0.3)
    
    # –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
    plt.subplot(2, 2, 4)
    cm = results[0.0]['confusion_matrix']  # –ë–µ–∑ —à—É–º–∞
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (–±–µ–∑ —à—É–º–∞)')
    plt.colorbar()
    tick_marks = np.arange(len(tree_types))
    plt.xticks(tick_marks, tree_types, rotation=45)
    plt.yticks(tick_marks, tree_types)
    
    plt.tight_layout()
    plt.savefig('1d_alexnet_noise_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ 1D-AlexNet –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    print("üå≤ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –†–ê–°–¢–ò–¢–ï–õ–¨–ù–û–°–¢–ò –° 1D-AlexNet")
    print("=" * 70)
    print("üìÑ –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞—Ç—å–µ —Å 1000 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ —à—É–º–∞")
    print("=" * 70)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    spectra, labels, tree_types = load_spectral_data()

    if len(spectra) == 0:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ!")
        return

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω–æ–π
    X, y, label_encoder, input_length = preprocess_spectra_for_1d_alexnet(spectra, labels, target_length=300)

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ 50/50
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)
    print(f"\nüìè –†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape}")
    print(f"  –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape}")

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    if TF_AVAILABLE:
        print("\nüöÄ –°–æ–∑–¥–∞–Ω–∏–µ 1D-AlexNet –≤ TensorFlow...")
        model = create_1d_alexnet_tensorflow((input_length, 1), len(tree_types))
        
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        history = model.fit(
            X_train_scaled.reshape(-1, input_length, 1),
            y_train,
            validation_data=(X_test_scaled.reshape(-1, input_length, 1), y_test),
            epochs=100,
            batch_size=32,
            verbose=1
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.save('1d_alexnet_vegetation_classifier.h5')
        
    else:
        print("\nü§ñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π 1D-AlexNet...")
        model = simulate_1d_alexnet_training(X_train_scaled, y_train, X_test_scaled, y_test, len(tree_types))

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–º —à—É–º–æ–º
    # –£—Ä–æ–≤–Ω–∏ —à—É–º–∞ 1%, 5%, 10% (–≤ –≤–∏–¥–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π)
    noise_levels = [0.0, 0.01, 0.05, 0.1]
    
    results = test_with_gaussian_noise_1000_realizations(
        model, X_test_scaled, y_test, tree_types, noise_levels
    )

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    plot_noise_analysis(results, tree_types)

    print("\n" + "="*70)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–≥–ª–∞—Å–Ω–æ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ —Å—Ç–∞—Ç—å–∏:")
    print("   - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö 50/50")
    print("   - 1000 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π –≥–∞—É—Å—Å–æ–≤—Å–∫–æ–≥–æ —à—É–º–∞ –Ω–∞ —É—Ä–æ–≤–Ω—è—Ö 1%, 5%, 10%")
    print("   - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º")
    print("   - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ª–æ–∂–Ω–æ–π —Ç—Ä–µ–≤–æ–≥–∏ (FPR)")
    print("="*70)

if __name__ == "__main__":
    main() 