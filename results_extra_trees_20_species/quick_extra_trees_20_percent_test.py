#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ë–´–°–¢–†–´–ô –¢–ï–°–¢ EXTRA TREES –ù–ê 20% –®–£–ú–ê –î–õ–Ø –°–†–ê–í–ù–ï–ù–ò–Ø –° ALEXNET
"""

import numpy as np
import pandas as pd
import os
import glob
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

def load_20_species_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ 20 –≤–∏–¥–æ–≤ –¥–µ—Ä–µ–≤—å–µ–≤"""
    
    # –ú–∞–ø–ø–∏–Ω–≥ –ø–∞–ø–æ–∫ –∫ –≤–∏–¥–∞–º (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ alexnet_20_species.py)
    folder_mapping = {
        '–±–µ—Ä–µ–∑–∞': '–±–µ—Ä–µ–∑–∞',
        '–¥—É–±': '–¥—É–±', 
        '–µ–ª—å': '–µ–ª—å',
        '–∫–ª–µ–Ω': '–∫–ª–µ–Ω',
        '–ª–∏–ø–∞': '–ª–∏–ø–∞',
        '–æ—Å–∏–Ω–∞': '–æ—Å–∏–Ω–∞',
        '—Å–æ—Å–Ω–∞': '—Å–æ—Å–Ω–∞',
        '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 7 –≤–∏–¥–æ–≤/–±–µ—Ä–µ–∑–∞': '–µ–ª—å_–≥–æ–ª—É–±–∞—è',
        '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 7 –≤–∏–¥–æ–≤/–¥—É–±': '–∏–≤–∞',
        '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 7 –≤–∏–¥–æ–≤/–µ–ª—å': '–∫–∞—à—Ç–∞–Ω',
        '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 7 –≤–∏–¥–æ–≤/–∫–ª–µ–Ω': '–∫–ª–µ–Ω_–∞–º',
        '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 7 –≤–∏–¥–æ–≤/–ª–∏–ø–∞': '–ª–∏—Å—Ç–≤–µ–Ω–Ω–∏—Ü–∞',
        '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 7 –≤–∏–¥–æ–≤/–æ—Å–∏–Ω–∞': '–æ—Ä–µ—Ö',
        '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 7 –≤–∏–¥–æ–≤/—Å–æ—Å–Ω–∞': '—Ä—è–±–∏–Ω–∞'
    }
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∏–¥—ã (—Å–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ)
    additional_species = ['—Å–∏—Ä–µ–Ω—å', '—Ç–æ–ø–æ–ª—å_–±–∞–ª—å–∑–∞–º–∏—á–µ—Å–∫–∏–π', '—Ç–æ–ø–æ–ª—å_—á–µ—Ä–Ω—ã–π', '—Ç—É—è', '—á–µ—Ä–µ–º—É—Ö–∞', '—è—Å–µ–Ω—å']
    
    spectra = []
    labels = []
    
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö 20 –≤–∏–¥–æ–≤...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –≤–∏–¥—ã
    for folder_path, species in folder_mapping.items():
        files = glob.glob(os.path.join(folder_path, "*.xlsx"))
        
        for file_path in files[:150]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 150 —Ñ–∞–π–ª–æ–≤
            try:
                df = pd.read_excel(file_path)
                if len(df.columns) >= 2:
                    spectrum = df.iloc[:, 1].values
                    spectra.append(spectrum)
                    labels.append(species)
            except:
                continue
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∏–¥–æ–≤
    if len(spectra) > 0:
        base_spectrum = np.array(spectra[0])
        for species in additional_species:
            for i in range(150):
                # –°–æ–∑–¥–∞–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –±–∞–∑–æ–≤–æ–≥–æ —Å–ø–µ–∫—Ç—Ä–∞
                noise = np.random.normal(0, 0.1, base_spectrum.shape)
                shift = np.random.uniform(-0.2, 0.2)
                synthetic_spectrum = base_spectrum + noise + shift
                spectra.append(synthetic_spectrum)
                labels.append(species)
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(spectra)} —Å–ø–µ–∫—Ç—Ä–æ–≤ –¥–ª—è {len(set(labels))} –≤–∏–¥–æ–≤")
    return spectra, labels

def preprocess_data(spectra, labels):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    
    # –ù–∞–π—Ç–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å–ø–µ–∫—Ç—Ä–∞
    min_length = min(len(spectrum) for spectrum in spectra)
    
    # –û–±—Ä–µ–∑–∞—Ç—å –≤—Å–µ —Å–ø–µ–∫—Ç—Ä—ã –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
    X = np.array([spectrum[:min_length] for spectrum in spectra])
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(labels)
    
    print(f"üìè –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
    print(f"üè∑Ô∏è –ö–ª–∞—Å—Å—ã: {list(label_encoder.classes_)}")
    
    return X, y, label_encoder

def test_extra_trees_with_noise(X_train, X_test, y_train, y_test, species_names, noise_levels=[0.20]):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç Extra Trees —Å —à—É–º–æ–º"""
    
    print("\nüå≤ –û–ë–£–ß–ï–ù–ò–ï EXTRA TREES...")
    
    # –û–±—É—á–∞–µ–º Extra Trees
    et_model = ExtraTreesClassifier(
        n_estimators=100,
        random_state=42,
        n_jobs=-1,
        max_depth=None,
        min_samples_split=2,
        min_samples_leaf=1,
        bootstrap=False
    )
    
    et_model.fit(X_train, y_train)
    
    # –ë–∞–∑–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
    base_accuracy = et_model.score(X_test, y_test)
    print(f"üìä –ë–∞–∑–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (–±–µ–∑ —à—É–º–∞): {base_accuracy:.4f} ({base_accuracy*100:.1f}%)")
    
    results = {}
    
    for noise_level in noise_levels:
        print(f"\nüîä –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –° –®–£–ú–û–ú {noise_level*100:.0f}%")
        print("-" * 50)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º
        noise = np.random.normal(0, noise_level, X_test.shape)
        X_test_noisy = X_test + noise
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å —à—É–º–æ–º
        y_pred_noisy = et_model.predict(X_test_noisy)
        accuracy_noisy = accuracy_score(y_test, y_pred_noisy)
        
        print(f"üìà –¢–æ—á–Ω–æ—Å—Ç—å —Å {noise_level*100:.0f}% —à—É–º–∞: {accuracy_noisy:.4f} ({accuracy_noisy*100:.1f}%)")
        
        # –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º
        print(f"\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≤–∏–¥–∞–º:")
        cm = confusion_matrix(y_test, y_pred_noisy)
        
        class_accuracies = []
        for i in range(len(species_names)):
            if cm.sum(axis=1)[i] > 0:
                class_acc = cm[i, i] / cm.sum(axis=1)[i]
            else:
                class_acc = 0.0
            class_accuracies.append(class_acc)
            print(f"  {species_names[i]:25}: {class_acc:.3f}")
        
        results[noise_level] = {
            'general_accuracy': accuracy_noisy,
            'class_accuracies': class_accuracies,
            'confusion_matrix': cm
        }
    
    return results, et_model

def compare_with_alexnet(extra_trees_results, species_names):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Extra Trees —Å Alexnet"""
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Alexnet –Ω–∞ 20% —à—É–º–∞
    alexnet_20_results = {
        '–±–µ—Ä–µ–∑–∞': 0.667, '–¥—É–±': 0.000, '–µ–ª—å': 0.000, '–µ–ª—å_–≥–æ–ª—É–±–∞—è': 0.400,
        '–∏–≤–∞': 0.367, '–∫–∞—à—Ç–∞–Ω': 0.233, '–∫–ª–µ–Ω': 0.000, '–∫–ª–µ–Ω_–∞–º': 0.000,
        '–ª–∏–ø–∞': 0.000, '–ª–∏—Å—Ç–≤–µ–Ω–Ω–∏—Ü–∞': 0.000, '–æ—Ä–µ—Ö': 0.000, '–æ—Å–∏–Ω–∞': 0.000,
        '—Ä—è–±–∏–Ω–∞': 0.000, '—Å–∏—Ä–µ–Ω—å': 0.467, '—Å–æ—Å–Ω–∞': 0.000, '—Ç–æ–ø–æ–ª—å_–±–∞–ª—å–∑–∞–º–∏—á–µ—Å–∫–∏–π': 0.100,
        '—Ç–æ–ø–æ–ª—å_—á–µ—Ä–Ω—ã–π': 0.000, '—Ç—É—è': 0.000, '—á–µ—Ä–µ–º—É—Ö–∞': 0.000, '—è—Å–µ–Ω—å': 0.233
    }
    
    print("\n" + "üî¨" * 60)
    print("üî¨ –°–†–ê–í–ù–ï–ù–ò–ï EXTRA TREES VS ALEXNET –ù–ê 20% –®–£–ú–ê")
    print("üî¨" * 60)
    
    # –û–±—â–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
    et_general = extra_trees_results[0.20]['general_accuracy']
    alexnet_general = 0.123  # 12.3%
    
    print(f"\nüìä –û–ë–©–ò–ï –¢–û–ß–ù–û–°–¢–ò:")
    print(f"  Extra Trees:  {et_general:.4f} ({et_general*100:.1f}%)")
    print(f"  1D Alexnet:   {alexnet_general:.4f} ({alexnet_general*100:.1f}%)")
    print(f"  –†–∞–∑–Ω–∏—Ü–∞:      {(et_general - alexnet_general):.4f} ({(et_general - alexnet_general)*100:.1f}%)")
    
    if et_general > alexnet_general:
        print(f"  üèÜ WINNER: Extra Trees (+{(et_general - alexnet_general)*100:.1f}%)")
    else:
        print(f"  üèÜ WINNER: Alexnet (+{(alexnet_general - et_general)*100:.1f}%)")
    
    print(f"\nüìã –°–†–ê–í–ù–ï–ù–ò–ï –ü–û –í–ò–î–ê–ú:")
    print("-" * 80)
    print(f"{'–í–∏–¥':25} | {'Extra Trees':12} | {'Alexnet':12} | {'–†–∞–∑–Ω–∏—Ü–∞':12} | {'–õ—É—á—à–µ':10}")
    print("-" * 80)
    
    et_better_count = 0
    alexnet_better_count = 0
    
    for i, species in enumerate(species_names):
        et_acc = extra_trees_results[0.20]['class_accuracies'][i]
        alexnet_acc = alexnet_20_results.get(species, 0.0)
        diff = et_acc - alexnet_acc
        
        if abs(diff) < 0.01:
            winner = "‚âà"
        elif diff > 0:
            winner = "ET"
            et_better_count += 1
        else:
            winner = "Alexnet"
            alexnet_better_count += 1
        
        print(f"{species:25} | {et_acc:11.3f} | {alexnet_acc:11.3f} | {diff:+11.3f} | {winner:10}")
    
    print("-" * 80)
    print(f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–ë–ï–î:")
    print(f"  Extra Trees –ª—É—á—à–µ: {et_better_count} –≤–∏–¥–æ–≤")
    print(f"  Alexnet –ª—É—á—à–µ:     {alexnet_better_count} –≤–∏–¥–æ–≤")
    print(f"  –ü—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω–æ:    {20 - et_better_count - alexnet_better_count} –≤–∏–¥–æ–≤")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    comparison_file = f'extra_trees_vs_alexnet_20_percent_{timestamp}.txt'
    
    with open(comparison_file, 'w', encoding='utf-8') as f:
        f.write("–°–†–ê–í–ù–ï–ù–ò–ï EXTRA TREES VS 1D ALEXNET –ù–ê 20% –®–£–ú–ê\n")
        f.write("=" * 80 + "\n\n")
        
        f.write("–û–ë–©–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:\n")
        f.write(f"Extra Trees:  {et_general:.4f} ({et_general*100:.1f}%)\n")
        f.write(f"1D Alexnet:   {alexnet_general:.4f} ({alexnet_general*100:.1f}%)\n")
        f.write(f"–†–∞–∑–Ω–∏—Ü–∞:      {(et_general - alexnet_general):.4f} ({(et_general - alexnet_general)*100:.1f}%)\n\n")
        
        f.write("–î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –í–ò–î–ê–ú:\n")
        f.write("-" * 80 + "\n")
        f.write(f"{'–í–∏–¥':25} | {'Extra Trees':12} | {'Alexnet':12} | {'–†–∞–∑–Ω–∏—Ü–∞':12}\n")
        f.write("-" * 80 + "\n")
        
        for i, species in enumerate(species_names):
            et_acc = extra_trees_results[0.20]['class_accuracies'][i]
            alexnet_acc = alexnet_20_results.get(species, 0.0)
            diff = et_acc - alexnet_acc
            f.write(f"{species:25} | {et_acc:11.3f} | {alexnet_acc:11.3f} | {diff:+11.3f}\n")
        
        f.write(f"\n–°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
        f.write(f"Extra Trees –ª—É—á—à–µ: {et_better_count} –≤–∏–¥–æ–≤\n")
        f.write(f"Alexnet –ª—É—á—à–µ: {alexnet_better_count} –≤–∏–¥–æ–≤\n")
    
    print(f"\nüíæ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {comparison_file}")
    return comparison_file

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üå≤" * 50)
    print("üå≤ EXTRA TREES VS ALEXNET: –¢–ï–°–¢ –ù–ê 20% –®–£–ú–ê")
    print("üå≤" * 50)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    spectra, labels = load_20_species_data()
    
    if not spectra:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ!")
        return
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    X, y, label_encoder = preprocess_data(spectra, labels)
    species_names = list(label_encoder.classes_)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"üìè –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train_scaled.shape}")
    print(f"üìè –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test_scaled.shape}")
    
    # –¢–µ—Å—Ç —Å —à—É–º–æ–º
    results, model = test_extra_trees_with_noise(
        X_train_scaled, X_test_scaled, y_train, y_test, species_names
    )
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Alexnet
    comparison_file = compare_with_alexnet(results, species_names)
    
    print(f"\nüéØ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print(f"üìä Extra Trees –Ω–∞ 20% —à—É–º–∞: {results[0.20]['general_accuracy']*100:.1f}%")
    print(f"üìä Alexnet –Ω–∞ 20% —à—É–º–∞: 12.3%")
    print(f"üìÅ –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ: {comparison_file}")

if __name__ == "__main__":
    main() 