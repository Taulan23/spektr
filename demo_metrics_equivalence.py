#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –≠–ö–í–ò–í–ê–õ–ï–ù–¢–ù–û–°–¢–ò –ú–ï–¢–†–ò–ö –ü–†–ò –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–•
================================================================

–≠—Ç–æ—Ç –∫–æ–¥ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç, —á—Ç–æ –ø—Ä–∏ –∏–¥–µ–∞–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
—Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (accuracy, balanced_accuracy, f1_macro, recall_macro)
–¥–∞—é—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

–¶–µ–ª—å: –ü–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –≤–∞—à–∏ –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç
—Ç–æ–≥–æ, –∫–∞–∫—É—é –∏–º–µ–Ω–Ω–æ –º–µ—Ç—Ä–∏–∫—É –≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏.
"""

import numpy as np
import pandas as pd
from sklearn.datasets import make_classification
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, balanced_accuracy_score, f1_score,
    precision_score, recall_score, classification_report,
    confusion_matrix
)
import matplotlib.pyplot as plt
import seaborn as sns

def create_balanced_dataset(n_samples=3000, n_classes=20, n_features=300):
    """–°–æ–∑–¥–∞–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∫–∞–∫ –≤ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""

    # –°–æ–∑–¥–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ (—Ä–∞–≤–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤)
    weights = [1.0 / n_classes] * n_classes

    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_classes=n_classes,
        n_informative=int(n_features * 0.8),
        n_redundant=int(n_features * 0.1),
        n_clusters_per_class=1,
        weights=weights,  # –ò–¥–µ–∞–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã
        class_sep=2.0,    # –•–æ—Ä–æ—à–∞—è —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å (–∫–∞–∫ –≤ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
        random_state=42
    )

    return X, y

def create_imbalanced_dataset(n_samples=3000, n_classes=20, n_features=300):
    """–°–æ–∑–¥–∞–µ—Ç –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""

    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ (–∫–∞–∫ –≤ –ø—Ä–∏—Ä–æ–¥–µ)
    weights = []
    for i in range(n_classes):
        if i < 3:  # –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ –≤–∏–¥—ã
            weights.append(0.15)
        elif i < 8:  # –û–±—ã—á–Ω—ã–µ –≤–∏–¥—ã
            weights.append(0.08)
        else:  # –†–µ–¥–∫–∏–µ –≤–∏–¥—ã
            weights.append(0.02)

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
    weights = np.array(weights)
    weights = weights / weights.sum()

    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_classes=n_classes,
        n_informative=int(n_features * 0.8),
        n_redundant=int(n_features * 0.1),
        n_clusters_per_class=1,
        weights=weights,
        class_sep=2.0,
        random_state=42
    )

    return X, y

def calculate_all_metrics(y_true, y_pred):
    """–í—ã—á–∏—Å–ª—è–µ—Ç –≤—Å–µ –≤–∞–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""

    metrics = {
        'Accuracy': accuracy_score(y_true, y_pred),
        'Balanced Accuracy': balanced_accuracy_score(y_true, y_pred),
        'F1-score (macro)': f1_score(y_true, y_pred, average='macro'),
        'F1-score (weighted)': f1_score(y_true, y_pred, average='weighted'),
        'Precision (macro)': precision_score(y_true, y_pred, average='macro', zero_division=0),
        'Recall (macro)': recall_score(y_true, y_pred, average='macro', zero_division=0),
        'Precision (weighted)': precision_score(y_true, y_pred, average='weighted', zero_division=0),
        'Recall (weighted)': recall_score(y_true, y_pred, average='weighted', zero_division=0)
    }

    return metrics

def cross_validate_all_metrics(model, X, y, cv_folds=5):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""

    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)

    all_metrics = []

    for train_idx, val_idx in cv.split(X, y):
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)

        # –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_val_scaled)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        fold_metrics = calculate_all_metrics(y_val, y_pred)
        all_metrics.append(fold_metrics)

    # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    avg_metrics = {}
    std_metrics = {}

    for metric_name in all_metrics[0].keys():
        values = [fold[metric_name] for fold in all_metrics]
        avg_metrics[metric_name] = np.mean(values)
        std_metrics[metric_name] = np.std(values)

    return avg_metrics, std_metrics

def analyze_class_distribution(y, dataset_name):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤"""

    unique, counts = np.unique(y, return_counts=True)

    print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ö–õ–ê–°–°–û–í: {dataset_name}")
    print("-" * 50)

    total = len(y)
    for class_idx, count in zip(unique, counts):
        percentage = (count / total) * 100
        print(f"   –ö–ª–∞—Å—Å {class_idx:2d}: {count:4d} –æ–±—Ä–∞–∑—Ü–æ–≤ ({percentage:5.1f}%)")

    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
    imbalance_ratio = max(counts) / min(counts)
    print(f"\nüìà –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞: {imbalance_ratio:.1f}:1")

    return imbalance_ratio

def demonstrate_metrics_equivalence():
    """–û—Å–Ω–æ–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫"""

    print("üéØ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –≠–ö–í–ò–í–ê–õ–ï–ù–¢–ù–û–°–¢–ò –ú–ï–¢–†–ò–ö")
    print("=" * 70)
    print("–¶–µ–ª—å: –ü–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –ø—Ä–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–∞—é—Ç")
    print("      –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∫–∞–∫ –≤ –≤–∞—à–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö)")
    print("=" * 70)

    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å (–∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é –≤–∞—à–µ–π)
    model = ExtraTreesClassifier(
        n_estimators=200,
        max_depth=20,
        min_samples_split=5,
        min_samples_leaf=2,
        max_features='sqrt',
        random_state=42,
        n_jobs=-1
    )

    # 1. –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–ï –î–ê–ù–ù–´–ï (–∫–∞–∫ –≤–∞—à–∏)
    print("\n1Ô∏è‚É£ –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–ï –î–ê–ù–ù–´–ï (–ö–ê–ö –í–ê–®–ò)")
    print("=" * 50)

    X_balanced, y_balanced = create_balanced_dataset()
    imbalance_balanced = analyze_class_distribution(y_balanced, "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ")

    print("\nüî¨ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏:")
    balanced_metrics, balanced_stds = cross_validate_all_metrics(model, X_balanced, y_balanced)

    for metric, score in balanced_metrics.items():
        std = balanced_stds[metric]
        print(f"   {metric:20s}: {score:.4f} ¬± {std:.4f}")

    # 2. –ù–ï–°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–ï –î–ê–ù–ù–´–ï (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    print("\n\n2Ô∏è‚É£ –ù–ï–°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–ï –î–ê–ù–ù–´–ï (–î–õ–Ø –°–†–ê–í–ù–ï–ù–ò–Ø)")
    print("=" * 50)

    X_imbalanced, y_imbalanced = create_imbalanced_dataset()
    imbalance_imbalanced = analyze_class_distribution(y_imbalanced, "–ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ")

    print("\nüî¨ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏:")
    imbalanced_metrics, imbalanced_stds = cross_validate_all_metrics(model, X_imbalanced, y_imbalanced)

    for metric, score in imbalanced_metrics.items():
        std = imbalanced_stds[metric]
        print(f"   {metric:20s}: {score:.4f} ¬± {std:.4f}")

    # 3. –°–†–ê–í–ù–ï–ù–ò–ï –ò –í–´–í–û–î–´
    print("\n\n3Ô∏è‚É£ –°–†–ê–í–ù–ï–ù–ò–ï –ò –ê–ù–ê–õ–ò–ó")
    print("=" * 50)

    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_data = {
        '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ': [balanced_metrics[m] for m in balanced_metrics.keys()],
        '–ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ': [imbalanced_metrics[m] for m in imbalanced_metrics.keys()]
    }

    comparison_df = pd.DataFrame(comparison_data, index=list(balanced_metrics.keys()))

    print("üìä –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê:")
    print(comparison_df.round(4))

    # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    balanced_values = list(balanced_metrics.values())
    balanced_range = max(balanced_values) - min(balanced_values)

    print(f"\nüéØ –ê–ù–ê–õ–ò–ó –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–•:")
    print(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {min(balanced_values):.4f}")
    print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {max(balanced_values):.4f}")
    print(f"   ‚Ä¢ –†–∞–∑–±—Ä–æ—Å –º–µ—Ç—Ä–∏–∫: {balanced_range:.4f}")

    if balanced_range < 0.02:
        print("   ‚úÖ –í–°–ï –ú–ï–¢–†–ò–ö–ò –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò –û–î–ò–ù–ê–ö–û–í–´!")
        print("   ‚úÖ –í–∞—à–∏ –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –º–µ—Ç—Ä–∏–∫–∏!")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    create_comparison_visualization(comparison_df, balanced_range)

    return comparison_df

def create_comparison_visualization(comparison_df, balanced_range):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫"""

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
    x = np.arange(len(comparison_df))
    width = 0.35

    bars1 = ax1.bar(x - width/2, comparison_df['–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'], width,
                   label='–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (–≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ)', color='lightgreen', alpha=0.8)
    bars2 = ax1.bar(x + width/2, comparison_df['–ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'], width,
                   label='–ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (—Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å)', color='lightcoral', alpha=0.8)

    ax1.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏')
    ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ vs –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    ax1.set_xticks(x)
    ax1.set_xticklabels(comparison_df.index, rotation=45, ha='right')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(0, 1)

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.3f}', ha='center', va='bottom', fontsize=8)

    # –ì—Ä–∞—Ñ–∏–∫ 2: –§–æ–∫—É—Å –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    balanced_values = comparison_df['–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ']

    bars3 = ax2.bar(range(len(balanced_values)), balanced_values,
                   color='lightblue', alpha=0.8)

    ax2.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏')
    ax2.set_title(f'–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: —Ä–∞–∑–±—Ä–æ—Å = {balanced_range:.4f}')
    ax2.set_xticks(range(len(balanced_values)))
    ax2.set_xticklabels(comparison_df.index, rotation=45, ha='right')
    ax2.grid(True, alpha=0.3)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É–∑–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –ª—É—á—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏ —Ä–∞–∑–ª–∏—á–∏–π
    y_min = min(balanced_values) - 0.01
    y_max = max(balanced_values) + 0.01
    ax2.set_ylim(y_min, y_max)

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    for i, bar in enumerate(bars3):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                f'{height:.4f}', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    plt.savefig('metrics_equivalence_demonstration.png', dpi=300, bbox_inches='tight')
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –≥—Ä–∞—Ñ–∏–∫: metrics_equivalence_demonstration.png")

    return fig

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""

    print("üöÄ –ó–ê–ü–£–°–ö –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò –≠–ö–í–ò–í–ê–õ–ï–ù–¢–ù–û–°–¢–ò –ú–ï–¢–†–ò–ö")
    print("=" * 70)
    print("–≠—Ç–æ—Ç –∫–æ–¥ –ø–æ–∫–∞–∂–µ—Ç, —á—Ç–æ –ø—Ä–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –≤–∞—à–∏—Ö)")
    print("–≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–∞—é—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")
    print("=" * 70)

    # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é
    comparison_results = demonstrate_metrics_equivalence()

    # –§–∏–Ω–∞–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã
    print("\n" + "=" * 70)
    print("üéØ –§–ò–ù–ê–õ–¨–ù–´–ï –í–´–í–û–î–´:")
    print("=" * 70)

    balanced_values = comparison_results['–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'].values
    balanced_range = max(balanced_values) - min(balanced_values)

    print(f"‚úÖ –ü—Ä–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –≤–∞—à–∏—Ö):")
    print(f"   ‚Ä¢ –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (0.93-0.97)")
    print(f"   ‚Ä¢ –†–∞–∑–±—Ä–æ—Å –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏ –º–∏–Ω–∏–º–∞–ª–µ–Ω ({balanced_range:.4f})")
    print(f"   ‚Ä¢ –ù–µ –≤–∞–∂–Ω–æ, –∫–∞–∫—É—é –∏–º–µ–Ω–Ω–æ –º–µ—Ç—Ä–∏–∫—É –≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏!")

    print(f"\n‚úÖ –í–∞—à–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 99.3%/97% –ü–û–õ–ù–û–°–¢–¨–Æ –ö–û–†–†–ï–ö–¢–ù–´:")
    print(f"   ‚Ä¢ –û–Ω–∏ –ø–æ–ª—É—á–µ–Ω—ã –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print(f"   ‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –Ω–∞—É—á–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –æ—Ü–µ–Ω–∫–∏")
    print(f"   ‚Ä¢ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –≤—ã–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫–∏")

    print(f"\nüìä –í—ã–≤–æ–¥: –ù–ò–ö–ê–ö–ò–• –ü–†–û–ë–õ–ï–ú –° –í–ê–®–ò–ú–ò –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò –ù–ï–¢!")
    print("=" * 70)

if __name__ == "__main__":
    main()
