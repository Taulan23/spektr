import os
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import GradientBoostingClassifier
import warnings
warnings.filterwarnings('ignore')

def load_spectral_data_enhanced():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    tree_types = ['–±–µ—Ä–µ–∑–∞', '–¥—É–±', '–µ–ª—å', '–∫–ª–µ–Ω', '–ª–∏–ø–∞', '–æ—Å–∏–Ω–∞', '—Å–æ—Å–Ω–∞']
    all_spectra = []
    all_labels = []
    
    print("üåø –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    print("="*70)
    
    for tree_type in tree_types:
        folder_path = os.path.join('.', tree_type)
        if os.path.exists(folder_path):
            excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))
            print(f"üìÅ {tree_type}: {len(excel_files)} —Ñ–∞–π–ª–æ–≤")
            
            for file_path in excel_files:
                try:
                    df = pd.read_excel(file_path)
                    
                    if df.shape[1] >= 2:
                        spectrum = df.iloc[:, 1].values
                        spectrum = spectrum[~np.isnan(spectrum)]
                        
                        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (–º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è)
                        if len(spectrum) >= 100:
                            # –ú—è–≥–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –≤—ã–±—Ä–æ—Å–æ–≤ (–∑–∞ 5 —Å–∏–≥–º)
                            if len(spectrum) > 50:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                                mean_val = np.mean(spectrum)
                                std_val = np.std(spectrum)
                                if std_val > 0:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –Ω–æ–ª—å
                                    mask = np.abs(spectrum - mean_val) <= 5 * std_val
                                    spectrum = spectrum[mask]
                            
                            if len(spectrum) >= 50:  # –ü–æ–Ω–∏–∂–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
                                all_spectra.append(spectrum)
                                all_labels.append(tree_type)
                            
                except Exception as e:
                    continue
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_spectra)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–ø–µ–∫—Ç—Ä–æ–≤")
    return all_spectra, all_labels, tree_types

def create_optimized_model_ensemble():
    """–°–æ–∑–¥–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    models = {
        'Deep_Neural_Network': MLPClassifier(
            hidden_layer_sizes=(2048, 1024, 512, 256, 128),  # –ë–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∞—è —Å–µ—Ç—å
            activation='relu',
            solver='adam',
            max_iter=3000,  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ —ç–ø–æ—Ö
            random_state=42,
            early_stopping=True,
            validation_fraction=0.2,
            learning_rate_init=0.0005,  # –ú–µ–Ω—å—à–∏–π learning rate
            batch_size=16,  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π batch size
            alpha=0.0001,  # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
            beta_1=0.9,
            beta_2=0.999,
            n_iter_no_change=50  # –ë–æ–ª—å—à–µ —Ç–µ—Ä–ø–µ–Ω–∏—è –¥–ª—è early stopping
        ),
        'Wide_Neural_Network': MLPClassifier(
            hidden_layer_sizes=(3072, 1536, 768, 384),  # –®–∏—Ä–æ–∫–∞—è —Å–µ—Ç—å
            activation='relu',
            solver='adam',
            max_iter=2500,
            random_state=43,
            early_stopping=True,
            validation_fraction=0.2,
            learning_rate_init=0.0003,
            batch_size=8,  # –ï—â–µ –º–µ–Ω—å—à–∏–π batch –¥–ª—è –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
            alpha=0.0001
        ),
        'Gradient_Boost_Optimized': GradientBoostingClassifier(
            n_estimators=1000,  # –ú–Ω–æ–≥–æ –¥–µ—Ä–µ–≤—å–µ–≤
            learning_rate=0.05,  # –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            max_depth=10,
            random_state=42,
            subsample=0.8,
            max_features='sqrt',
            min_samples_split=5,
            min_samples_leaf=2
        )
    }
    
    return models

def enhanced_data_augmentation(X, y, augment_factor=3):
    """–£—Å–∏–ª–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    print(f"üîÑ –£—Å–∏–ª–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (—Ñ–∞–∫—Ç–æ—Ä {augment_factor})...")
    
    augmented_X = [X]
    augmented_y = [y]
    
    for i in range(augment_factor):
        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —à—É–º–∞
        noise_level = 0.005 * (i + 1)
        X_noisy = X + np.random.normal(0, noise_level, X.shape)
        
        # –°–¥–≤–∏–≥–∏
        shift_range = min(5, X.shape[1] // 20)
        shifts = np.random.randint(-shift_range, shift_range + 1, X.shape[0])
        X_shifted = np.array([np.roll(spectrum, s) for spectrum, s in zip(X, shifts)])
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        scale_factors = np.random.uniform(0.95, 1.05, (X.shape[0], 1))
        X_scaled = X * scale_factors
        
        augmented_X.extend([X_noisy, X_shifted, X_scaled])
        augmented_y.extend([y, y, y])
    
    X_augmented = np.vstack(augmented_X)
    y_augmented = np.hstack(augmented_y)
    
    print(f"  üìä –†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {X_augmented.shape}")
    return X_augmented, y_augmented

def train_optimized_ensemble(models, X_train, y_train, X_val, y_val):
    """–û–±—É—á–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π –∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é"""
    print("ü§ñ –û–±—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π...")
    
    trained_models = {}
    best_model = None
    best_accuracy = 0
    best_name = ""
    
    for name, model in models.items():
        print(f"\n  üîß –û–±—É—á–µ–Ω–∏–µ {name}...")
        print(f"    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {model.get_params()}")
        
        # –û–±—É—á–µ–Ω–∏–µ
        model.fit(X_train, y_train)
        
        # –û—Ü–µ–Ω–∫–∞
        train_accuracy = model.score(X_train, y_train)
        val_accuracy = model.score(X_val, y_val)
        
        print(f"    –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {train_accuracy:.4f}")
        print(f"    –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {val_accuracy:.4f}")
        
        trained_models[name] = model
        
        if val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            best_model = model
            best_name = name
    
    print(f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_name} —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {best_accuracy:.4f}")
    return best_model, trained_models

def test_with_target_comparison(model, X_test, y_test, tree_types, n_realizations=1000):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø—Ä—è–º—ã–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º —Å —Ü–µ–ª–µ–≤—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–∑ —Å—Ç–∞—Ç—å–∏"""
    print("\n" + "="*70)
    print("üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –° –¶–ï–õ–ï–í–´–ú–ò –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò (1000 –†–ï–ê–õ–ò–ó–ê–¶–ò–ô)")
    print("="*70)
    
    # –¶–µ–ª–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ —Å—Ç–∞—Ç—å–∏
    target_results = {
        '–±–µ—Ä–µ–∑–∞': [0.944, 0.939, 0.919],
        '–¥—É–±': [0.783, 0.820, 0.827],
        '–∫–ª–µ–Ω': [0.818, 0.821, 0.830],
        '–ª–∏–ø–∞': [0.931, 0.875, 0.791],
        '–æ—Å–∏–Ω–∞': [0.821, 0.751, 0.640],
        '–µ–ª—å': [0.914, 0.908, 0.881],
        '—Å–æ—Å–Ω–∞': [0.854, 0.832, 0.792]
    }
    
    noise_levels = [0.01, 0.05, 0.1]  # Œ¥ = 1%, 5%, 10%
    noise_names = ['Œ¥=1%', 'Œ¥=5%', 'Œ¥=10%']
    
    results = {}
    
    print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –° –¶–ï–õ–ï–í–´–ú–ò –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò –ò–ó –°–¢–ê–¢–¨–ò:")
    print("="*70)
    print(f"{'–ü–æ—Ä–æ–¥–∞':<8} | {'Œ¥=1%':<12} | {'Œ¥=5%':<12} | {'Œ¥=10%':<12}")
    print(f"{'–¥–µ—Ä–µ–≤–∞':<8} | {'Pc   Pe':<12} | {'Pc   Pe':<12} | {'Pc   Pe':<12}")
    print("-" * 70)
    
    for noise_idx, noise_level in enumerate(noise_levels):
        print(f"\nüîä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —à—É–º–æ–º {noise_level*100}% (1000 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π)...")
        
        accuracies = []
        class_correct = np.zeros(len(tree_types))
        class_total = np.zeros(len(tree_types))
        all_fps = np.zeros(len(tree_types))
        
        # 1000 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π
        for realization in range(n_realizations):
            if realization % 200 == 0:
                print(f"  –†–µ–∞–ª–∏–∑–∞—Ü–∏—è {realization + 1}/1000...")
            
            # –ì–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º —Å –Ω—É–ª–µ–≤—ã–º —Å—Ä–µ–¥–Ω–∏–º
            if noise_level > 0:
                noise = np.random.normal(0, noise_level, X_test.shape).astype(np.float32)
                X_test_noisy = X_test + noise
            else:
                X_test_noisy = X_test
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            y_pred = model.predict(X_test_noisy)
            accuracy = accuracy_score(y_test, y_pred)
            accuracies.append(accuracy)
            
            # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–π –ø–æ –∫–ª–∞—Å—Å–∞–º
            for i in range(len(tree_types)):
                mask = (y_test == i)
                if np.sum(mask) > 0:
                    class_total[i] += np.sum(mask)
                    class_correct[i] += np.sum((y_pred[mask] == i))
            
            # –ü–æ–¥—Å—á–µ—Ç –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π –¥–ª—è –ø–µ—Ä–≤–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
            if realization == 0:
                cm = confusion_matrix(y_test, y_pred)
                for i in range(len(tree_types)):
                    FP = cm.sum(axis=0)[i] - cm[i, i]
                    TN = cm.sum() - cm.sum(axis=0)[i] - cm.sum(axis=1)[i] + cm[i, i]
                    all_fps[i] = FP / (FP + TN) if (FP + TN) != 0 else 0
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        class_accuracies = class_correct / np.maximum(class_total, 1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results[noise_level] = {
            'class_accuracies': class_accuracies,
            'false_positive_rates': all_fps,
            'mean_accuracy': np.mean(accuracies),
            'std_accuracy': np.std(accuracies)
        }
        
        print(f"    –°—Ä–µ–¥–Ω—è—è –æ–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {np.mean(accuracies):.4f} ¬± {np.std(accuracies):.4f}")
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ —Ç–∞–±–ª–∏—Ü—ã –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ
    print("\n" + "="*70)
    print("üìã –§–ò–ù–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í (—Ñ–æ—Ä–º–∞—Ç —Å—Ç–∞—Ç—å–∏):")
    print("="*70)
    print(f"{'–ü–æ—Ä–æ–¥–∞':<8} | {'Œ¥=1%':<12} | {'Œ¥=5%':<12} | {'Œ¥=10%':<12}")
    print(f"{'–¥–µ—Ä–µ–≤–∞':<8} | {'Pc   Pe':<12} | {'Pc   Pe':<12} | {'Pc   Pe':<12}")
    print("-" * 70)
    
    total_diff = 0
    count_comparisons = 0
    
    for i, tree in enumerate(tree_types):
        row = f"{tree:<8} |"
        
        for noise_idx, noise_level in enumerate(noise_levels):
            our_pc = results[noise_level]['class_accuracies'][i]
            our_pe = results[noise_level]['false_positive_rates'][i]
            target_pc = target_results[tree][noise_idx]
            
            # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ Pe –∏–∑ —Å—Ç–∞—Ç—å–∏ (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)
            target_pe_map = {
                '–±–µ—Ä–µ–∑–∞': [0.014, 0.020, 0.021],
                '–¥—É–±': [0.001, 0.003, 0.006],
                '–∫–ª–µ–Ω': [0.016, 0.016, 0.023],
                '–ª–∏–ø–∞': [0.045, 0.040, 0.039],
                '–æ—Å–∏–Ω–∞': [0.011, 0.014, 0.022],
                '–µ–ª—å': [0.039, 0.053, 0.075],
                '—Å–æ—Å–Ω–∞': [0.030, 0.029, 0.031]
            }
            
            target_pe = target_pe_map[tree][noise_idx]
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–æ—Å—Ç—å —Å —Ü–µ–ª—å—é
            diff_pc = abs(our_pc - target_pc)
            total_diff += diff_pc
            count_comparisons += 1
            
            # –°—Ç–∞—Ç—É—Å –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏
            status = "‚úÖ" if diff_pc < 0.03 else "‚ö†Ô∏è" if diff_pc < 0.06 else "‚ùå"
            
            row += f" {our_pc:.3f} {our_pe:.3f} |"
        
        print(row)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        target_row = f"(—Ü–µ–ª—å)   |"
        for noise_idx in range(3):
            target_pc = target_results[tree][noise_idx]
            target_pe = target_pe_map[tree][noise_idx]
            target_row += f" {target_pc:.3f} {target_pe:.3f} |"
        print(target_row)
        print("-" * 70)
    
    avg_diff = total_diff / count_comparisons
    print(f"\nüìä –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê:")
    print(f"–°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–æ—Å—Ç—å —Å —Ü–µ–ª–µ–≤—ã–º–∏ Pc: {avg_diff:.3f}")
    
    if avg_diff < 0.03:
        print("üéâ –û–¢–õ–ò–ß–ù–û! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—á–µ–Ω—å –±–ª–∏–∑–∫–∏ –∫ —Å—Ç–∞—Ç—å–µ!")
    elif avg_diff < 0.06:
        print("‚úÖ –•–û–†–û–®–û! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∏–µ–º–ª–µ–º–æ –±–ª–∏–∑–∫–∏ –∫ —Å—Ç–∞—Ç—å–µ.")
    else:
        print("‚ö†Ô∏è –ù—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è.")
    
    return results

def plot_final_comparison(results, tree_types):
    """–§–∏–Ω–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    target_results = {
        '–±–µ—Ä–µ–∑–∞': [0.944, 0.939, 0.919],
        '–¥—É–±': [0.783, 0.820, 0.827],
        '–∫–ª–µ–Ω': [0.818, 0.821, 0.830],
        '–ª–∏–ø–∞': [0.931, 0.875, 0.791],
        '–æ—Å–∏–Ω–∞': [0.821, 0.751, 0.640],
        '–µ–ª—å': [0.914, 0.908, 0.881],
        '—Å–æ—Å–Ω–∞': [0.854, 0.832, 0.792]
    }
    
    noise_levels = [0.01, 0.05, 0.1]
    
    plt.figure(figsize=(20, 15))
    
    # –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ –≤–∏–¥–∞–º
    for i, tree in enumerate(tree_types):
        plt.subplot(3, 3, i + 1)
        
        # –¶–µ–ª–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        target_vals = target_results[tree]
        plt.plot([n*100 for n in noise_levels], target_vals, 
                'ro-', label='–°—Ç–∞—Ç—å—è (—Ü–µ–ª—å)', linewidth=3, markersize=10)
        
        # –ù–∞—à–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        our_vals = [results[noise]['class_accuracies'][i] for noise in noise_levels]
        plt.plot([n*100 for n in noise_levels], our_vals, 
                'bs-', label='–ù–∞—à–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', linewidth=3, markersize=10)
        
        plt.xlabel('–£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ (%)', fontsize=12)
        plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å (Pc)', fontsize=12)
        plt.title(f'{tree.upper()}', fontsize=14, fontweight='bold')
        plt.legend(fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.ylim(0.6, 1.0)
    
    # –û–±—â–∏–π –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    plt.subplot(3, 3, 8)
    
    # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –≤—Å–µ–º –≤–∏–¥–∞–º
    target_means = [np.mean([target_results[tree][i] for tree in tree_types]) 
                   for i in range(3)]
    our_means = [np.mean([results[noise]['class_accuracies']]) for noise in noise_levels]
    
    plt.plot([n*100 for n in noise_levels], target_means, 
            'ro-', label='–°—Ç–∞—Ç—å—è (—Å—Ä–µ–¥–Ω–µ–µ)', linewidth=4, markersize=12)
    plt.plot([n*100 for n in noise_levels], our_means, 
            'bs-', label='–ù–∞—à–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Å—Ä–µ–¥–Ω–µ–µ)', linewidth=4, markersize=12)
    
    plt.xlabel('–£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ (%)', fontsize=12)
    plt.ylabel('–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å', fontsize=12)
    plt.title('–û–ë–©–ï–ï –°–†–ê–í–ù–ï–ù–ò–ï', fontsize=14, fontweight='bold')
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # –¢–∞–±–ª–∏—Ü–∞ —Ä–∞–∑–Ω–æ—Å—Ç–µ–π
    plt.subplot(3, 3, 9)
    plt.axis('off')
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ä–∞–∑–Ω–æ—Å—Ç–µ–π
    differences = []
    for tree in tree_types:
        row = []
        for i, noise in enumerate(noise_levels):
            our_val = results[noise]['class_accuracies'][tree_types.index(tree)]
            target_val = target_results[tree][i]
            diff = abs(our_val - target_val)
            row.append(f'{diff:.3f}')
        differences.append(row)
    
    table = plt.table(cellText=differences,
                     rowLabels=tree_types,
                     colLabels=['Œ¥=1%', 'Œ¥=5%', 'Œ¥=10%'],
                     cellLoc='center',
                     loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.5)
    plt.title('–†–∞–∑–Ω–æ—Å—Ç–∏ —Å —Ü–µ–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏', fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('optimized_final_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("üéØ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –†–ê–°–¢–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 70)
    print("üéØ –¶–ï–õ–¨: –î–û–°–¢–ò–ß–¨ –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ò–ó –ù–ê–£–ß–ù–û–ô –°–¢–ê–¢–¨–ò")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    spectra, labels, tree_types = load_spectral_data_enhanced()
    
    if len(spectra) == 0:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ!")
        return
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    lengths = [len(s) for s in spectra]
    target_length = min(lengths)
    X = np.array([spectrum[:target_length] for spectrum in spectra], dtype=np.float32)
    
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(labels)
    
    print(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
    
    # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.67, random_state=42, stratify=y_temp
    )
    
    print(f"üìè –û–±—É—á–∞—é—â–∞—è: {X_train.shape}, –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è: {X_val.shape}, –¢–µ—Å—Ç–æ–≤–∞—è: {X_test.shape}")
    
    # –£—Å–∏–ª–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
    X_train_aug, y_train_aug = enhanced_data_augmentation(X_train, y_train, augment_factor=2)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_aug)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è
    models = create_optimized_model_ensemble()
    best_model, all_models = train_optimized_ensemble(models, X_train_scaled, y_train_aug, X_val_scaled, y_val)
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø—Ä—è–º—ã–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º —Å —Å—Ç–∞—Ç—å–µ–π
    results = test_with_target_comparison(best_model, X_test_scaled, y_test, tree_types, n_realizations=1000)
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
    plot_final_comparison(results, tree_types)
    
    print("\n" + "="*70)
    print("‚úÖ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–ø—Ä—è–º—É—é —Å—Ä–∞–≤–Ω–µ–Ω—ã —Å —Ü–µ–ª–µ–≤—ã–º–∏ –∏–∑ —Å—Ç–∞—Ç—å–∏")
    print("üìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏: optimized_final_comparison.png")
    print("üöÄ –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —ç–ø–æ—Ö–∏/–±–∞—Ç—á–∏")
    print("="*70)

if __name__ == "__main__":
    main() 