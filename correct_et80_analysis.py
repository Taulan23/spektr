#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–†–ê–í–ò–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –§–ê–ô–õ–ê et80_10.xlsx
–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –≤–∏–¥ "–±–µ—Ä–µ–∑–∞"
"""

import pandas as pd
import numpy as np

def correct_et80_analysis():
    """–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ et80_10.xlsx"""
    
    print("="*80)
    print("üìä –ü–†–ê–í–ò–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –§–ê–ô–õ–ê et80_10.xlsx")
    print("="*80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
    df = pd.read_excel('et80_10.xlsx')
    
    print(f"üìã –°–¢–†–£–ö–¢–£–†–ê –§–ê–ô–õ–ê:")
    print(f"   ‚Ä¢ –†–∞–∑–º–µ—Ä: {df.shape}")
    print(f"   ‚Ä¢ –°—Ç—Ä–æ–∫: {len(df)}")
    print(f"   ‚Ä¢ –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")
    
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤ (—Å—Ç—Ä–æ–∫–∞ 8)
    headers = df.iloc[8, 1:].values
    print(f"\nüìã –ó–ê–ì–û–õ–û–í–ö–ò –°–¢–û–õ–ë–¶–û–í:")
    for i, header in enumerate(headers):
        if pd.notna(header):
            print(f"   ‚Ä¢ –°—Ç–æ–ª–±–µ—Ü {i+1}: {header}")
    
    # –î–∞–Ω–Ω—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å–æ —Å—Ç—Ä–æ–∫–∏ 9
    data_start = 9
    
    # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
    total_samples = 0
    for i in range(data_start, len(df)):
        if any(pd.notna(val) for val in df.iloc[i, 1:].values):
            total_samples += 1
    
    print(f"\nüìä –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {total_samples}")
    print(f"   ‚Ä¢ –í–∏–¥: –±–µ—Ä–µ–∑–∞ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –≤ —Ñ–∞–π–ª–µ)")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print(f"\nüìà –ê–ù–ê–õ–ò–ó –ü–†–ê–í–ò–õ–¨–ù–´–• –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ô:")
    
    # –ò—â–µ–º —Å—Ç–æ–ª–±–µ—Ü "–ü–û –±–µ—Ä–µ–∑–∞" (–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ)
    po_beresa_col = None
    for j in range(1, len(df.columns)):
        if pd.notna(headers[j-1]) and "–ü–û –±–µ—Ä–µ–∑–∞" in str(headers[j-1]):
            po_beresa_col = j
            break
    
    if po_beresa_col is None:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü '–ü–û –±–µ—Ä–µ–∑–∞'")
        return
    
    # –°—á–∏—Ç–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±–µ—Ä–µ–∑—ã
    correct_beresa = 0
    for i in range(data_start, len(df)):
        if pd.notna(df.iloc[i, po_beresa_col]) and df.iloc[i, po_beresa_col] == 1:
            correct_beresa += 1
    
    accuracy_beresa = correct_beresa / total_samples * 100 if total_samples > 0 else 0
    
    print(f"   ‚Ä¢ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±–µ—Ä–µ–∑—ã: {correct_beresa}/{total_samples}")
    print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±–µ—Ä–µ–∑—ã: {accuracy_beresa:.1f}%")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–∂–Ω—ã–µ —Ç—Ä–µ–≤–æ–≥–∏
    print(f"\nüö® –ê–ù–ê–õ–ò–ó –õ–û–ñ–ù–´–• –¢–†–ï–í–û–ì:")
    
    false_alarms = {}
    for j in range(1, len(df.columns)):
        if pd.notna(headers[j-1]) and "–õ–¢" in str(headers[j-1]):
            species_name = str(headers[j-1]).replace("–õ–¢ ", "")
            false_alarm_count = 0
            
            for i in range(data_start, len(df)):
                if pd.notna(df.iloc[i, j]) and df.iloc[i, j] == 1:
                    false_alarm_count += 1
            
            false_alarms[species_name] = false_alarm_count
            false_alarm_rate = false_alarm_count / total_samples * 100 if total_samples > 0 else 0
            print(f"   ‚Ä¢ {species_name}: {false_alarm_count} –ª–æ–∂–Ω—ã—Ö —Ç—Ä–µ–≤–æ–≥ ({false_alarm_rate:.1f}%)")
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_false_alarms = sum(false_alarms.values())
    total_false_alarm_rate = total_false_alarms / total_samples * 100 if total_samples > 0 else 0
    
    print(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   ‚Ä¢ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {correct_beresa}")
    print(f"   ‚Ä¢ –õ–æ–∂–Ω—ã–µ —Ç—Ä–µ–≤–æ–≥–∏: {total_false_alarms}")
    print(f"   ‚Ä¢ –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy_beresa:.1f}%")
    print(f"   ‚Ä¢ –û–±—â–∞—è —á–∞—Å—Ç–æ—Ç–∞ –ª–æ–∂–Ω—ã—Ö —Ç—Ä–µ–≤–æ–≥: {total_false_alarm_rate:.1f}%")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –Ω–∞—à–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ù–ê–®–ò–ú–ò –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò:")
    print(f"   ‚Ä¢ et80_10.xlsx (–±–µ—Ä–µ–∑–∞): {accuracy_beresa:.1f}%")
    print(f"   ‚Ä¢ –ù–∞—à–∞ –º–æ–¥–µ–ª—å (–±–µ—Ä–µ–∑–∞, 10% —à—É–º–∞): ~96.7% (29/30)")
    print(f"   ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞: {accuracy_beresa - 96.7:.1f}%")
    
    if accuracy_beresa < 96.7:
        print(f"   ‚Ä¢ –í—ã–≤–æ–¥: –í —Ñ–∞–π–ª–µ et80_10.xlsx —Ç–æ—á–Ω–æ—Å—Ç—å –ù–ò–ñ–ï –Ω–∞ {96.7 - accuracy_beresa:.1f}%")
        print(f"   ‚Ä¢ –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –≤–∞—à–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –æ –ø–∞–¥–µ–Ω–∏–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏!")
    else:
        print(f"   ‚Ä¢ –í—ã–≤–æ–¥: –í —Ñ–∞–π–ª–µ et80_10.xlsx —Ç–æ—á–Ω–æ—Å—Ç—å –≤—ã—à–µ –Ω–∞ {accuracy_beresa - 96.7:.1f}%")
    
    # –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –æ—à–∏–±–æ–∫
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –û–°–ù–û–í–ù–´–• –û–®–ò–ë–û–ö:")
    sorted_false_alarms = sorted(false_alarms.items(), key=lambda x: x[1], reverse=True)
    
    print(f"   ‚Ä¢ –¢–æ–ø-5 –ª–æ–∂–Ω—ã—Ö —Ç—Ä–µ–≤–æ–≥:")
    for i, (species, count) in enumerate(sorted_false_alarms[:5]):
        rate = count / total_samples * 100 if total_samples > 0 else 0
        print(f"     {i+1}. {species}: {count} ({rate:.1f}%)")
    
    print("="*80)

if __name__ == "__main__":
    correct_et80_analysis() 