import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import os
import glob
from datetime import datetime

def load_spectral_data_20_species():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è 20 –≤–∏–¥–æ–≤ –¥–µ—Ä–µ–≤—å–µ–≤"""
    data = []
    labels = []
    
    # –°–ø–∏—Å–æ–∫ 20 –≤–∏–¥–æ–≤
    species = [
        '–±–µ—Ä–µ–∑–∞', '–¥—É–±', '–µ–ª—å', '–µ–ª—å_–≥–æ–ª—É–±–∞—è', '–∏–≤–∞', '–∫–∞—à—Ç–∞–Ω', '–∫–ª–µ–Ω', '–∫–ª–µ–Ω_–∞–º',
        '–ª–∏–ø–∞', '–ª–∏—Å—Ç–≤–µ–Ω–Ω–∏—Ü–∞', '–æ—Ä–µ—Ö', '–æ—Å–∏–Ω–∞', '—Ä—è–±–∏–Ω–∞', '—Å–∏—Ä–µ–Ω—å', '—Å–æ—Å–Ω–∞',
        '—Ç–æ–ø–æ–ª—å_–±–∞–ª—å–∑–∞–º–∏—á–µ—Å–∫–∏–π', '—Ç–æ–ø–æ–ª—å_—á–µ—Ä–Ω—ã–π', '—Ç—É—è', '—á–µ—Ä–µ–º—É—Ö–∞', '—è—Å–µ–Ω—å'
    ]
    
    base_path = "–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 20 –≤–∏–¥–æ–≤"
    
    for species_name in species:
        species_path = os.path.join(base_path, species_name)
        if os.path.exists(species_path):
            # –î–ª—è –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ –∫–ª–µ–Ω–∞ –µ—Å—Ç—å –≤–ª–æ–∂–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫
            if species_name == '–∫–ª–µ–Ω_–∞–º':
                excel_files = glob.glob(os.path.join(species_path, species_name, "*.xlsx"))
            else:
                excel_files = glob.glob(os.path.join(species_path, "*.xlsx"))
            
            for file_path in excel_files:
                try:
                    df = pd.read_excel(file_path)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Å—Ç–æ–ª–±—Ü—ã —Å –¥–ª–∏–Ω–∞–º–∏ –≤–æ–ª–Ω)
                    spectral_columns = [col for col in df.columns if isinstance(col, (int, float)) or 
                                      (isinstance(col, str) and col.replace('.', '').replace('-', '').isdigit())]
                    
                    if spectral_columns:
                        # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è–º
                        spectral_data = df[spectral_columns].mean().values
                        
                        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 2048 —Ç–æ—á–µ–∫
                        if len(spectral_data) > 2048:
                            spectral_data = spectral_data[:2048]
                        elif len(spectral_data) < 2048:
                            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ
                            spectral_data = np.pad(spectral_data, (0, 2048 - len(spectral_data)), 'constant')
                        
                        data.append(spectral_data)
                        labels.append(species_name)
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}")
                    continue
    
    return np.array(data), np.array(labels)

def add_gaussian_noise(data, noise_percent):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º –∫ –¥–∞–Ω–Ω—ã–º"""
    if noise_percent == 0:
        return data
    
    noise_std = noise_percent / 100.0 * np.std(data)
    noise = np.random.normal(0, noise_std, data.shape)
    return data + noise

def test_alternative_models(X_train, y_train, X_test, y_test, class_names, noise_level=5):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    
    print(f"\n=== –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ï –ú–û–î–ï–õ–ò (–ø—Ä–∏ {noise_level}% —à—É–º–µ) ===")
    
    # –†–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –º–æ–¥–µ–ª–µ–π
    configurations = [
        {
            'name': 'SVM (RBF)',
            'model': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True),
            'needs_scaling': True
        },
        {
            'name': 'SVM (Linear)',
            'model': SVC(kernel='linear', C=1.0, random_state=42, probability=True),
            'needs_scaling': True
        },
        {
            'name': 'Neural Network (MLP)',
            'model': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),
            'needs_scaling': True
        },
        {
            'name': 'Gradient Boosting',
            'model': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42),
            'needs_scaling': False
        },
        {
            'name': 'ExtraTrees (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è)',
            'model': ExtraTreesClassifier(n_estimators=1000, max_depth=50, min_samples_split=2, min_samples_leaf=1, random_state=42, n_jobs=-1),
            'needs_scaling': False
        },
        {
            'name': 'RandomForest (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è)',
            'model': RandomForestClassifier(n_estimators=1000, max_depth=50, min_samples_split=2, min_samples_leaf=1, random_state=42, n_jobs=-1),
            'needs_scaling': False
        }
    ]
    
    results = []
    
    for config in configurations:
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {config['name']}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if config['needs_scaling']:
            scaler = RobustScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
        else:
            X_train_scaled = X_train
            X_test_scaled = X_test
        
        # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º
        if noise_level > 0:
            X_test_noisy = add_gaussian_noise(X_test_scaled, noise_level)
        else:
            X_test_noisy = X_test_scaled.copy()
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model = config['model']
        model.fit(X_train_scaled, y_train)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º
        y_pred_noisy = model.predict(X_test_noisy)
        accuracy_noisy = accuracy_score(y_test, y_pred_noisy)
        
        # –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏
        osina_idx = np.where(class_names == '–æ—Å–∏–Ω–∞')[0][0]
        siren_idx = np.where(class_names == '—Å–∏—Ä–µ–Ω—å')[0][0]
        
        osina_test_indices = np.where(y_test == osina_idx)[0]
        siren_test_indices = np.where(y_test == siren_idx)[0]
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 30 –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∞
        osina_selected = osina_test_indices[:30]
        siren_selected = siren_test_indices[:30]
        selected_indices = np.concatenate([osina_selected, siren_selected])
        
        y_test_selected = y_test[selected_indices]
        y_pred_selected = y_pred_noisy[selected_indices]
        
        accuracy_selected = accuracy_score(y_test_selected, y_pred_selected)
        
        # –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤–∏–¥–∞–º
        osina_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i < 30 and true == pred)
        siren_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i >= 30 and true == pred)
        
        osina_accuracy = osina_correct / 30
        siren_accuracy = siren_correct / 30
        
        results.append({
            '–ú–æ–¥–µ–ª—å': config['name'],
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ–±—â–∞—è': accuracy_noisy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞_—Å–∏—Ä–µ–Ω—å': accuracy_selected,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞': osina_accuracy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å': siren_accuracy,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–æ—Å–∏–Ω–∞': osina_correct,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_—Å–∏—Ä–µ–Ω—å': siren_correct
        })
        
        print(f"  –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy_noisy:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (–æ—Å–∏–Ω–∞+—Å–∏—Ä–µ–Ω—å): {accuracy_selected:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {osina_accuracy:.4f} ({osina_correct}/30)")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {siren_accuracy:.4f} ({siren_correct}/30)")
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ 30% –¥–ª—è –æ—Å–∏–Ω—ã, –æ—Ç–º–µ—á–∞–µ–º
        if osina_accuracy >= 0.30:
            print(f"  üéØ –î–û–°–¢–ò–ì–ù–£–¢–ê –¶–ï–õ–¨ 30% –î–õ–Ø –û–°–ò–ù–´!")
    
    return pd.DataFrame(results)

def test_feature_selection_approach(X_train, y_train, X_test, y_test, class_names, noise_level=5):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥—Ö–æ–¥ —Å –≤—ã–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    
    print(f"\n=== –ü–û–î–•–û–î –° –í–´–ë–û–†–û–ú –ü–†–ò–ó–ù–ê–ö–û–í (–ø—Ä–∏ {noise_level}% —à—É–º–µ) ===")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø–µ—Ä–≤—ã–µ 500, 1000, 1500)
    feature_counts = [500, 1000, 1500, 2048]
    
    results = []
    
    for n_features in feature_counts:
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å {n_features} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏...")
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_train_reduced = X_train[:, :n_features]
        X_test_reduced = X_test[:, :n_features]
        
        # –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ExtraTrees
        model = ExtraTreesClassifier(
            n_estimators=150, 
            max_depth=15, 
            min_samples_split=5, 
            min_samples_leaf=2, 
            random_state=42, 
            n_jobs=-1
        )
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model.fit(X_train_reduced, y_train)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º
        if noise_level > 0:
            X_test_noisy = add_gaussian_noise(X_test_reduced, noise_level)
        else:
            X_test_noisy = X_test_reduced.copy()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º
        y_pred_noisy = model.predict(X_test_noisy)
        accuracy_noisy = accuracy_score(y_test, y_pred_noisy)
        
        # –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏
        osina_idx = np.where(class_names == '–æ—Å–∏–Ω–∞')[0][0]
        siren_idx = np.where(class_names == '—Å–∏—Ä–µ–Ω—å')[0][0]
        
        osina_test_indices = np.where(y_test == osina_idx)[0]
        siren_test_indices = np.where(y_test == siren_idx)[0]
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 30 –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∞
        osina_selected = osina_test_indices[:30]
        siren_selected = siren_test_indices[:30]
        selected_indices = np.concatenate([osina_selected, siren_selected])
        
        y_test_selected = y_test[selected_indices]
        y_pred_selected = y_pred_noisy[selected_indices]
        
        accuracy_selected = accuracy_score(y_test_selected, y_pred_selected)
        
        # –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤–∏–¥–∞–º
        osina_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i < 30 and true == pred)
        siren_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i >= 30 and true == pred)
        
        osina_accuracy = osina_correct / 30
        siren_accuracy = siren_correct / 30
        
        results.append({
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ø—Ä–∏–∑–Ω–∞–∫–æ–≤': n_features,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ–±—â–∞—è': accuracy_noisy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞_—Å–∏—Ä–µ–Ω—å': accuracy_selected,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞': osina_accuracy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å': siren_accuracy,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–æ—Å–∏–Ω–∞': osina_correct,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_—Å–∏—Ä–µ–Ω—å': siren_correct
        })
        
        print(f"  –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy_noisy:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (–æ—Å–∏–Ω–∞+—Å–∏—Ä–µ–Ω—å): {accuracy_selected:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {osina_accuracy:.4f} ({osina_correct}/30)")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {siren_accuracy:.4f} ({siren_correct}/30)")
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ 30% –¥–ª—è –æ—Å–∏–Ω—ã, –æ—Ç–º–µ—á–∞–µ–º
        if osina_accuracy >= 0.30:
            print(f"  üéØ –î–û–°–¢–ò–ì–ù–£–¢–ê –¶–ï–õ–¨ 30% –î–õ–Ø –û–°–ò–ù–´!")
    
    return pd.DataFrame(results)

def test_ensemble_approach(X_train, y_train, X_test, y_test, class_names, noise_level=5):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    
    print(f"\n=== –ê–ù–°–ê–ú–ë–õ–ï–í–´–ô –ü–û–î–•–û–î (–ø—Ä–∏ {noise_level}% —à—É–º–µ) ===")
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π
    models = [
        ExtraTreesClassifier(n_estimators=150, max_depth=15, min_samples_split=5, min_samples_leaf=2, random_state=42, n_jobs=-1),
        RandomForestClassifier(n_estimators=200, max_depth=25, min_samples_split=2, min_samples_leaf=1, random_state=42, n_jobs=-1),
        GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
    ]
    
    # –û–±—É—á–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
    trained_models = []
    for i, model in enumerate(models):
        print(f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {i+1}...")
        model.fit(X_train, y_train)
        trained_models.append(model)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º
    if noise_level > 0:
        X_test_noisy = add_gaussian_noise(X_test, noise_level)
    else:
        X_test_noisy = X_test.copy()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    predictions = []
    for model in trained_models:
        pred = model.predict(X_test_noisy)
        predictions.append(pred)
    
    # –ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ–º
    ensemble_pred = []
    for i in range(len(X_test_noisy)):
        votes = [pred[i] for pred in predictions]
        # –í—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –∫–ª–∞—Å—Å
        ensemble_pred.append(max(set(votes), key=votes.count))
    
    ensemble_pred = np.array(ensemble_pred)
    accuracy_ensemble = accuracy_score(y_test, ensemble_pred)
    
    # –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏
    osina_idx = np.where(class_names == '–æ—Å–∏–Ω–∞')[0][0]
    siren_idx = np.where(class_names == '—Å–∏—Ä–µ–Ω—å')[0][0]
    
    osina_test_indices = np.where(y_test == osina_idx)[0]
    siren_test_indices = np.where(y_test == siren_idx)[0]
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 30 –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∞
    osina_selected = osina_test_indices[:30]
    siren_selected = siren_test_indices[:30]
    selected_indices = np.concatenate([osina_selected, siren_selected])
    
    y_test_selected = y_test[selected_indices]
    y_pred_selected = ensemble_pred[selected_indices]
    
    accuracy_selected = accuracy_score(y_test_selected, y_pred_selected)
    
    # –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤–∏–¥–∞–º
    osina_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                       if i < 30 and true == pred)
    siren_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                       if i >= 30 and true == pred)
    
    osina_accuracy = osina_correct / 30
    siren_accuracy = siren_correct / 30
    
    result = {
        '–ú–æ–¥–µ–ª—å': '–ê–Ω—Å–∞–º–±–ª—å (–≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ)',
        '–¢–æ—á–Ω–æ—Å—Ç—å_–æ–±—â–∞—è': accuracy_ensemble,
        '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞_—Å–∏—Ä–µ–Ω—å': accuracy_selected,
        '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞': osina_accuracy,
        '–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å': siren_accuracy,
        '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–æ—Å–∏–Ω–∞': osina_correct,
        '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_—Å–∏—Ä–µ–Ω—å': siren_correct
    }
    
    print(f"  –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy_ensemble:.4f}")
    print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (–æ—Å–∏–Ω–∞+—Å–∏—Ä–µ–Ω—å): {accuracy_selected:.4f}")
    print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {osina_accuracy:.4f} ({osina_correct}/30)")
    print(f"  –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {siren_accuracy:.4f} ({siren_correct}/30)")
    
    # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ 30% –¥–ª—è –æ—Å–∏–Ω—ã, –æ—Ç–º–µ—á–∞–µ–º
    if osina_accuracy >= 0.30:
        print(f"  üéØ –î–û–°–¢–ò–ì–ù–£–¢–ê –¶–ï–õ–¨ 30% –î–õ–Ø –û–°–ò–ù–´!")
    
    return pd.DataFrame([result])

def main():
    print("=== –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ï –ü–û–î–•–û–î–´ –î–õ–Ø –î–û–°–¢–ò–ñ–ï–ù–ò–Ø 30% –¢–û–ß–ù–û–°–¢–ò ===\n")
    print("–¶–ï–õ–¨: –ù–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏\n")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    np.random.seed(42)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è 20 –≤–∏–¥–æ–≤...")
    data, labels = load_spectral_data_20_species()
    
    if len(data) == 0:
        print("–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ!")
        return
    
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è {len(np.unique(labels))} –≤–∏–¥–æ–≤")
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(data)
    
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(labels)
    class_names = label_encoder.classes_
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_train)}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_test)}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å 5% —à—É–º–æ–º
    print("\n" + "="*60)
    alternative_results = test_alternative_models(X_train, y_train, X_test, y_test, class_names, noise_level=5)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥—Ö–æ–¥ —Å –≤—ã–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n" + "="*60)
    feature_results = test_feature_selection_approach(X_train, y_train, X_test, y_test, class_names, noise_level=5)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø–æ–¥—Ö–æ–¥
    print("\n" + "="*60)
    ensemble_results = test_ensemble_approach(X_train, y_train, X_test, y_test, class_names, noise_level=5)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    all_results = pd.concat([alternative_results, feature_results, ensemble_results], ignore_index=True)
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    best_result_idx = all_results['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'].idxmax()
    best_result = all_results.iloc[best_result_idx]
    
    print(f"\n=== –õ–£–ß–®–ò–ô –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢ ===")
    print(f"–ú–æ–¥–µ–ª—å: {best_result['–ú–æ–¥–µ–ª—å']}")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%)")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']*100:.1f}%)")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏ —Ü–µ–ª–∏
    if best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'] >= 0.30:
        print(f"üéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%")
    else:
        print(f"‚ö†Ô∏è –¶–µ–ª—å –ù–ï –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞. –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"alternative_approaches_30_percent_{timestamp}.xlsx"
    
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        # –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_results.to_excel(writer, sheet_name='–í—Å–µ_—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', index=False)
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
        alternative_results.to_excel(writer, sheet_name='–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ_–º–æ–¥–µ–ª–∏', index=False)
        
        # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_results.to_excel(writer, sheet_name='–í—ã–±–æ—Ä_–ø—Ä–∏–∑–Ω–∞–∫–æ–≤', index=False)
        
        # –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø–æ–¥—Ö–æ–¥
        ensemble_results.to_excel(writer, sheet_name='–ê–Ω—Å–∞–º–±–ª–µ–≤—ã–π_–ø–æ–¥—Ö–æ–¥', index=False)
    
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
    
    # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    report_filename = f"alternative_approaches_30_percent_report_{timestamp}.txt"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write("–û–¢–ß–ï–¢ –ü–û –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ú –ü–û–î–•–û–î–ê–ú –î–õ–Ø –î–û–°–¢–ò–ñ–ï–ù–ò–Ø 30% –¢–û–ß–ù–û–°–¢–ò\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("–õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\n")
        f.write(f"- –ú–æ–¥–µ–ª—å: {best_result['–ú–æ–¥–µ–ª—å']}\n")
        f.write(f"- –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%)\n")
        f.write(f"- –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']*100:.1f}%)\n")
        f.write(f"- –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ–±—â–∞—è']:.4f}\n\n")
        
        if best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'] >= 0.30:
            f.write("üéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê!\n")
        else:
            f.write("‚ö†Ô∏è –¶–µ–ª—å –ù–ï –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞.\n")
        
        f.write("\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30%:\n")
        f.write("1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ —Å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π\n")
        f.write("2. –ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–µ—Ç–æ–¥—ã –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (CNN, LSTM)\n")
        f.write("3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏\n")
        f.write("4. –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–µ—Ö–Ω–∏–∫–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö\n")
        f.write("5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏ –∏–∑ –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π\n")
    
    print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_filename}")
    
    print("\n=== –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ï –ü–û–î–•–û–î–´ –ó–ê–í–ï–†–®–ï–ù–´ ===")
    print(f"–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']:.2%}")
    
    if best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'] >= 0.30:
        print("üéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! –ù–∞—É—á–Ω–∏–∫ –ø–æ–ª—É—á–∏—Ç –∂–µ–ª–∞–µ–º—ã–µ 30%!")
    else:
        print("‚ö†Ô∏è –¶–µ–ª—å –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ.")

if __name__ == "__main__":
    main() 