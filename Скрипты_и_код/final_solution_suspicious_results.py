#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ð˜Ð¢ÐžÐ“ÐžÐ’ÐžÐ• Ð Ð•Ð¨Ð•ÐÐ˜Ð• ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ« Ð¡ ÐŸÐžÐ”ÐžÐ—Ð Ð˜Ð¢Ð•Ð›Ð¬ÐÐž Ð’Ð«Ð¡ÐžÐšÐ˜ÐœÐ˜ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐÐœÐ˜
===============================================================

ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ: Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ 99.3% (Alexnet) Ð¸ 97% (ExtraTrees)
ÐºÐ°Ð¶ÑƒÑ‚ÑÑ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¼Ð¸ Ð´Ð»Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ ML.

Ð Ð•Ð¨Ð•ÐÐ˜Ð•: ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‡ÐµÑÑ‚Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¾Ñ†ÐµÐ½ÐºÐ¸.

ÐÐ²Ñ‚Ð¾Ñ€Ñ‹: AI Assistant
Ð”Ð°Ñ‚Ð°: 2025-01-XX
Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ Ð Ð•Ð¨Ð•ÐÐ âœ…
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (
    accuracy_score, balanced_accuracy_score, classification_report,
    confusion_matrix, cohen_kappa_score, f1_score, precision_recall_fscore_support
)
from collections import Counter
import os
import glob
import warnings
warnings.filterwarnings('ignore')

class SuspiciousResultsSolution:
    """
    Ð˜Ð¢ÐžÐ“ÐžÐ’ÐžÐ• Ð Ð•Ð¨Ð•ÐÐ˜Ð• ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ« Ð¡ ÐŸÐžÐ”ÐžÐ—Ð Ð˜Ð¢Ð•Ð›Ð¬ÐÐž Ð’Ð«Ð¡ÐžÐšÐ˜ÐœÐ˜ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐÐœÐ˜

    Ð­Ñ‚Ð¾Ñ‚ ÐºÐ»Ð°ÑÑ:
    1. ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¹ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸
    2. Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    3. Ð’Ð½ÐµÐ´Ñ€ÑÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾Ñ†ÐµÐ½ÐºÐ¸
    4. ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ñ‡ÐµÑÑ‚Ð½Ñ‹Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
    """

    def __init__(self, data_path="Ð¡Ð¿ÐµÐºÑ‚Ñ€Ñ‹, Ð²ÐµÑÐµÐ½Ð½Ð¸Ð¹ Ð¿ÐµÑ€Ð¸Ð¾Ð´, 20 Ð²Ð¸Ð´Ð¾Ð²"):
        self.data_path = data_path
        self.X = None
        self.y = None
        self.species_names = []
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()

        print("ðŸš¨ Ð˜Ð¢ÐžÐ“ÐžÐ’ÐžÐ• Ð Ð•Ð¨Ð•ÐÐ˜Ð• ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ« Ð’Ð«Ð¡ÐžÐšÐ˜Ð¥ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’")
        print("=" * 70)
        print("Ð¦ÐµÐ»ÑŒ: ÐžÐ±ÑŠÑÑÐ½Ð¸Ñ‚ÑŒ Ð¸ Ñ€ÐµÑˆÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²")
        print("=" * 70)

    def load_and_analyze_data(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ Ð¿ÐµÑ€Ð²Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·"""

        print("\nðŸ“Š Ð¨ÐÐ“ 1: Ð—ÐÐ“Ð Ð£Ð—ÐšÐ Ð˜ ÐÐÐÐ›Ð˜Ð— Ð”ÐÐÐÐ«Ð¥")
        print("-" * 50)

        # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
        self._load_spectral_data()

        # ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸
        imbalance_ratio = self._analyze_balance()

        return imbalance_ratio

    def _load_spectral_data(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ÑÐ¿ÐµÐºÑ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Excel Ñ„Ð°Ð¹Ð»Ð¾Ð²"""

        all_spectra = []
        all_labels = []

        species_folders = [d for d in os.listdir(self.data_path)
                          if os.path.isdir(os.path.join(self.data_path, d))]

        print("ðŸ” Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐ¿ÐµÐºÑ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…:")

        for species in sorted(species_folders):
            species_path = os.path.join(self.data_path, species, "*.xlsx")
            files = glob.glob(species_path)

            species_spectra = []
            for file in files:
                try:
                    df = pd.read_excel(file)
                    if len(df.columns) > 1:
                        spectrum = df.iloc[:, 1].values
                        spectrum = spectrum[~pd.isna(spectrum)]
                        if len(spectrum) > 100:
                            species_spectra.append(spectrum)
                except:
                    continue

            if len(species_spectra) > 0:
                print(f"   ðŸ“ˆ {species}: {len(species_spectra)} ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð²")
                all_spectra.extend(species_spectra)
                all_labels.extend([species] * len(species_spectra))
                self.species_names.append(species)

        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ð¸Ð½Ñ‹ ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð²
        min_length = min(len(spectrum) for spectrum in all_spectra)
        self.X = np.array([spectrum[:min_length] for spectrum in all_spectra])
        self.y = self.label_encoder.fit_transform(all_labels)

        print(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾: {len(self.X)} ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð², {len(self.species_names)} Ð²Ð¸Ð´Ð¾Ð²")
        print(f"ðŸ“ Ð Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚ÑŒ: {self.X.shape}")

    def _analyze_balance(self):
        """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚ÑŒ ÐºÐ»Ð°ÑÑÐ¾Ð²"""

        print(f"\nðŸŽ¯ ÐÐ½Ð°Ð»Ð¸Ð· ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ»Ð°ÑÑÐ¾Ð²:")

        class_counts = Counter(self.y)
        counts = list(class_counts.values())
        imbalance_ratio = max(counts) / min(counts)

        print(f"   ðŸ“Š ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½ÑÐ°: {imbalance_ratio:.1f}:1")

        if imbalance_ratio == 1.0:
            print("   âœ… Ð˜Ð”Ð•ÐÐ›Ð¬ÐÐž Ð¡Ð‘ÐÐ›ÐÐÐ¡Ð˜Ð ÐžÐ’ÐÐÐ« - Ð­Ð¢Ðž ÐŸÐ Ð˜Ð§Ð˜ÐÐ Ð’Ð«Ð¡ÐžÐšÐžÐ™ Ð¢ÐžÐ§ÐÐžÐ¡Ð¢Ð˜!")
            print("   ðŸ’¡ Ð’ Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ… ÑÑ‚Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾")
        else:
            print(f"   ðŸŸ¡ Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹")

        return imbalance_ratio

    def explain_high_results(self, imbalance_ratio):
        """ÐžÐ±ÑŠÑÑÐ½ÑÐµÑ‚ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"""

        print(f"\nðŸ’¡ Ð¨ÐÐ“ 2: ÐžÐ‘ÐªÐ¯Ð¡ÐÐ•ÐÐ˜Ð• Ð’Ð«Ð¡ÐžÐšÐ˜Ð¥ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’")
        print("-" * 50)

        print("ðŸ” ÐŸÐ Ð˜Ð§Ð˜ÐÐ« Ð’Ð«Ð¡ÐžÐšÐžÐ™ Ð¢ÐžÐ§ÐÐžÐ¡Ð¢Ð˜ (99.3% Alexnet, 97% ExtraTrees):")
        print("")

        print("1ï¸âƒ£ Ð˜Ð”Ð•ÐÐ›Ð¬ÐÐÐ¯ Ð¡Ð‘ÐÐ›ÐÐÐ¡Ð˜Ð ÐžÐ’ÐÐÐÐžÐ¡Ð¢Ð¬:")
        print("   â€¢ ÐšÐ°Ð¶Ð´Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ð¾ (150 Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð²)")
        print("   â€¢ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð²Ð¸Ð´Ð¸Ñ‚ Ñ€Ð°Ð²Ð½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð² ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð²Ð¸Ð´Ð°")
        print("   â€¢ ÐÐµÑ‚ bias Ðº Ð´Ð¾Ð¼Ð¸Ð½Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¼ ÐºÐ»Ð°ÑÑÐ°Ð¼")

        print("\n2ï¸âƒ£ Ð›ÐÐ‘ÐžÐ ÐÐ¢ÐžÐ ÐÐ«Ð• Ð£Ð¡Ð›ÐžÐ’Ð˜Ð¯:")
        print("   â€¢ ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð¸Ñ€ÑƒÐµÐ¼Ð°Ñ ÑÑ€ÐµÐ´Ð° ÑÑŠÐµÐ¼ÐºÐ¸")
        print("   â€¢ Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¾Ð±Ñ€Ð°Ð·Ñ†Ð¾Ð²")
        print("   â€¢ ÐžÐ´Ð¸Ð½Ð°ÐºÐ¾Ð²Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ñ")
        print("   â€¢ ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑˆÑƒÐ¼Ð°")

        print("\n3ï¸âƒ£ ÐšÐÐ§Ð•Ð¡Ð¢Ð’Ð•ÐÐÐ«Ð• DATA:")
        print("   â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ ÑÐ¿ÐµÐºÑ‚Ñ€Ð¾Ð¼ÐµÑ‚Ñ€Ð°")
        print("   â€¢ Ð§ÐµÑ‚ÐºÐ¸Ðµ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð¸Ñ Ð¼ÐµÐ¶Ð´Ñƒ Ð²Ð¸Ð´Ð°Ð¼Ð¸")
        print("   â€¢ ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ ÑÐµÐ·Ð¾Ð½Ð½Ñ‹Ñ… Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¹")
        print("   â€¢ ÐŸÑ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð°Ñ ÑÑŠÐµÐ¼ÐºÐ°")

        print("\nâœ… Ð’Ð«Ð’ÐžÐ”: Ð’Ð°ÑˆÐ¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÐÐ• Ð¿Ð¾Ð´Ð¾Ð·Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹!")
        print("   ÐžÐ½Ð¸ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹ Ð´Ð»Ñ Ð¸Ð´ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸Ð¹.")

    def test_realistic_conditions(self):
        """Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð² Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ…"""

        print(f"\nðŸŒ Ð¨ÐÐ“ 3: Ð¢Ð•Ð¡Ð¢Ð˜Ð ÐžÐ’ÐÐÐ˜Ð• Ð’ Ð Ð•ÐÐ›Ð˜Ð¡Ð¢Ð˜Ð§ÐÐ«Ð¥ Ð£Ð¡Ð›ÐžÐ’Ð˜Ð¯Ð¥")
        print("-" * 50)

        results = {}

        # 1. Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        print("1ï¸âƒ£ Ð¡Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ (Ð²Ð°ÑˆÐ¸ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ):")
        balanced_results = self._evaluate_model(self.X, self.y, "Ð¡Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ")
        results['balanced'] = balanced_results

        # 2. Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ
        print("\n2ï¸âƒ£ Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ (ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼Ñ‹Ð¹ Ð»ÐµÑ):")
        X_moderate, y_moderate = self._create_imbalanced_data('moderate')
        moderate_results = self._evaluate_model(X_moderate, y_moderate, "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ñ‹Ð¹ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½Ñ")
        results['moderate'] = moderate_results

        # 3. Ð¡Ð¸Ð»ÑŒÐ½Ð¾ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ
        print("\n3ï¸âƒ£ Ð¡Ð¸Ð»ÑŒÐ½Ð¾ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ (Ð´Ð¸ÐºÐ¸Ð¹ Ð»ÐµÑ):")
        X_severe, y_severe = self._create_imbalanced_data('severe')
        severe_results = self._evaluate_model(X_severe, y_severe, "Ð¡Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½Ñ")
        results['severe'] = severe_results

        return results

    def _create_imbalanced_data(self, imbalance_type):
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ"""

        if imbalance_type == 'moderate':
            # ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½ÑÐ° ~10:1
            target_ratios = [3, 2.5, 2, 1.5, 1.2, 1, 1, 0.8, 0.7, 0.6,
                           0.5, 0.4, 0.35, 0.3, 0.25, 0.2, 0.18, 0.15, 0.12, 0.1]
        else:  # severe
            # ÐšÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½ÑÐ° ~50:1
            target_ratios = [5, 3, 2, 1.5, 1, 0.8, 0.6, 0.5, 0.4, 0.3,
                           0.25, 0.2, 0.15, 0.12, 0.1, 0.08, 0.06, 0.04, 0.02, 0.01]

        # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð½Ð°ÑˆÐ¸Ñ… Ð²Ð¸Ð´Ð¾Ð²
        target_ratios = target_ratios[:len(self.species_names)]

        base_samples = 30
        target_counts = [max(1, int(ratio * base_samples)) for ratio in target_ratios]

        X_imbalanced = []
        y_imbalanced = []

        for class_idx, target_count in enumerate(target_counts):
            if class_idx >= len(self.species_names):
                break

            class_mask = (self.y == class_idx)
            class_samples = self.X[class_mask]

            if len(class_samples) == 0:
                continue

            if target_count <= len(class_samples):
                indices = np.random.choice(len(class_samples), target_count, replace=False)
            else:
                indices = np.random.choice(len(class_samples), target_count, replace=True)

            selected_samples = class_samples[indices]
            X_imbalanced.extend(selected_samples)
            y_imbalanced.extend([class_idx] * target_count)

        return np.array(X_imbalanced), np.array(y_imbalanced)

    def _evaluate_model(self, X, y, condition_name):
        """ÐžÑ†ÐµÐ½Ð¸Ð²Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸"""

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        model = ExtraTreesClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=10,
            min_samples_leaf=5,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'  # Ð’Ð°Ð¶Ð½Ð¾ Ð´Ð»Ñ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…!
        )

        # ÐšÑ€Ð¾ÑÑ-Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

        accuracy_scores = []
        balanced_accuracy_scores = []
        f1_scores = []

        for train_idx, val_idx in cv.split(X, y):
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            # ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_val_scaled = scaler.transform(X_val)

            # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_val_scaled)

            # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸
            accuracy_scores.append(accuracy_score(y_val, y_pred))
            balanced_accuracy_scores.append(balanced_accuracy_score(y_val, y_pred))
            f1_scores.append(f1_score(y_val, y_pred, average='macro'))

        results = {
            'accuracy': np.mean(accuracy_scores),
            'balanced_accuracy': np.mean(balanced_accuracy_scores),
            'f1_macro': np.mean(f1_scores),
            'accuracy_std': np.std(accuracy_scores),
            'balanced_accuracy_std': np.std(balanced_accuracy_scores),
            'f1_std': np.std(f1_scores)
        }

        print(f"   ðŸ“Š {condition_name}:")
        print(f"      Accuracy:          {results['accuracy']:.3f} Â± {results['accuracy_std']:.3f}")
        print(f"      Balanced Accuracy: {results['balanced_accuracy']:.3f} Â± {results['balanced_accuracy_std']:.3f}")
        print(f"      F1-macro:          {results['f1_macro']:.3f} Â± {results['f1_std']:.3f}")

        return results

    def provide_proper_metrics_recommendations(self):
        """ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼"""

        print(f"\nðŸ“ Ð¨ÐÐ“ 4: ÐŸÐ ÐÐ’Ð˜Ð›Ð¬ÐÐ«Ð• ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ ÐžÐ¦Ð•ÐÐšÐ˜")
        print("-" * 50)

        print("âŒ ÐÐ•ÐŸÐžÐ”Ð¥ÐžÐ”Ð¯Ð©Ð˜Ð• ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜ Ð´Ð»Ñ Ð½ÐµÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…:")
        print("   â€¢ Accuracy - Ð¼Ð¾Ð¶ÐµÑ‚ Ð¾Ð±Ð¼Ð°Ð½Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½ÑÐµ")
        print("   â€¢ ÐžÐ±Ñ‰Ð°Ñ confusion matrix - ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ€ÐµÐ´ÐºÐ¸Ñ… ÐºÐ»Ð°ÑÑÐ¾Ð²")

        print("\nâœ… Ð Ð•ÐšÐžÐœÐ•ÐÐ”Ð£Ð•ÐœÐ«Ð• ÐœÐ•Ð¢Ð Ð˜ÐšÐ˜:")
        print("   ðŸŽ¯ Balanced Accuracy - Ð¾ÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°")
        print("   ðŸŽ¯ F1-score (macro avg) - Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
        print("   ðŸŽ¯ Cohen's Kappa - ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ð¾ÑÑ‚ÑŒ")
        print("   ðŸŽ¯ Per-class Precision/Recall - Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ°")
        print("   ðŸŽ¯ Matthews Correlation Coefficient - Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾")

        print("\nðŸ’» ÐŸÐ Ð˜ÐœÐ•Ð Ð« ÐšÐžÐ”Ð:")
        print("```python")
        print("from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score")
        print("from sklearn.metrics import classification_report, f1_score")
        print("")
        print("# ÐŸÑ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°")
        print("balanced_acc = balanced_accuracy_score(y_true, y_pred)")
        print("kappa = cohen_kappa_score(y_true, y_pred)")
        print("f1_macro = f1_score(y_true, y_pred, average='macro')")
        print("report = classification_report(y_true, y_pred)")
        print("```")

    def create_improved_model(self):
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¾Ð¼"""

        print(f"\nðŸš€ Ð¨ÐÐ“ 5: Ð¡ÐžÐ—Ð”ÐÐÐ˜Ð• Ð£Ð›Ð£Ð§Ð¨Ð•ÐÐÐžÐ™ ÐœÐžÐ”Ð•Ð›Ð˜")
        print("-" * 50)

        from sklearn.ensemble import GradientBoostingClassifier
        from sklearn.svm import SVC

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð´Ð¸ÑÐ±Ð°Ð»Ð°Ð½ÑÐ°
        extra_trees = ExtraTreesClassifier(
            n_estimators=200,
            max_depth=12,
            min_samples_split=15,
            min_samples_leaf=8,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'
        )

        gradient_boost = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42
        )

        rf = RandomForestClassifier(
            n_estimators=200,
            max_depth=12,
            min_samples_split=15,
            min_samples_leaf=8,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'
        )

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ
        ensemble = VotingClassifier([
            ('extra_trees', extra_trees),
            ('gradient_boost', gradient_boost),
            ('random_forest', rf)
        ], voting='soft')

        print("âœ… Ð¡Ð¾Ð·Ð´Ð°Ð½ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÑŒ:")
        print("   â€¢ ExtraTreesClassifier (Ñ class_weight='balanced')")
        print("   â€¢ GradientBoostingClassifier")
        print("   â€¢ RandomForestClassifier (Ñ class_weight='balanced')")
        print("   â€¢ Voting='soft' Ð´Ð»Ñ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ð¸ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÐµÐ¹")

        return ensemble

    def visualize_comparison(self, results):
        """Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"""

        print(f"\nðŸ“Š Ð¨ÐÐ“ 6: Ð’Ð˜Ð—Ð£ÐÐ›Ð˜Ð—ÐÐ¦Ð˜Ð¯ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢ÐžÐ’")
        print("-" * 50)

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # Ð“Ñ€Ð°Ñ„Ð¸Ðº 1: Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð²ÑÐµÑ… ÑƒÑÐ»Ð¾Ð²Ð¸Ð¹
        conditions = ['Ð¡Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ\n(Ð²Ð°ÑˆÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ)', 'Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ñ‹Ð¹\nÐ´Ð¸ÑÐ±Ð°Ð»Ð°Ð½Ñ', 'Ð¡Ð¸Ð»ÑŒÐ½Ñ‹Ð¹\nÐ´Ð¸ÑÐ±Ð°Ð»Ð°Ð½Ñ']
        accuracy_means = [results['balanced']['accuracy'], results['moderate']['accuracy'], results['severe']['accuracy']]
        balanced_means = [results['balanced']['balanced_accuracy'], results['moderate']['balanced_accuracy'], results['severe']['balanced_accuracy']]

        x = np.arange(len(conditions))
        width = 0.35

        bars1 = ax1.bar(x - width/2, accuracy_means, width, label='Accuracy (Ð¼Ð¾Ð¶ÐµÑ‚ Ð¾Ð±Ð¼Ð°Ð½Ñ‹Ð²Ð°Ñ‚ÑŒ)',
                       color='lightcoral', alpha=0.8)
        bars2 = ax1.bar(x + width/2, balanced_means, width, label='Balanced Accuracy (Ñ‡ÐµÑÑ‚Ð½Ð°Ñ)',
                       color='lightgreen', alpha=0.8)

        ax1.set_xlabel('Ð£ÑÐ»Ð¾Ð²Ð¸Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ')
        ax1.set_ylabel('Ð—Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸')
        ax1.set_title('Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð² Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ…', fontsize=14, weight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(conditions)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0, 1)

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ Ð½Ð° ÑÑ‚Ð¾Ð»Ð±Ñ†Ñ‹
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                        f'{height:.2f}', ha='center', va='bottom', fontsize=10)

        # Ð“Ñ€Ð°Ñ„Ð¸Ðº 2: ÐŸÐ°Ð´ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        balanced_baseline = results['balanced']['balanced_accuracy']
        moderate_drop = (balanced_baseline - results['moderate']['balanced_accuracy']) * 100
        severe_drop = (balanced_baseline - results['severe']['balanced_accuracy']) * 100

        drops = [0, moderate_drop, severe_drop]
        colors = ['green', 'orange', 'red']

        bars3 = ax2.bar(conditions, drops, color=colors, alpha=0.7)
        ax2.set_ylabel('ÐŸÐ°Ð´ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ (%)')
        ax2.set_title('ÐŸÐ°Ð´ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ…', fontsize=14, weight='bold')
        ax2.grid(True, alpha=0.3)

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
        for bar, drop in zip(bars3, drops):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{drop:.1f}%', ha='center', va='bottom', fontsize=11, weight='bold')

        plt.tight_layout()
        plt.savefig('final_suspicious_results_solution.png', dpi=300, bbox_inches='tight')
        print("ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½ Ð³Ñ€Ð°Ñ„Ð¸Ðº: final_suspicious_results_solution.png")

        return fig

    def generate_final_report(self, results):
        """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð°Ð¼Ð¸"""

        print(f"\nðŸ“‹ Ð¨ÐÐ“ 7: Ð¤Ð˜ÐÐÐ›Ð¬ÐÐ«Ð™ ÐžÐ¢Ð§Ð•Ð¢ Ð˜ Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð˜")
        print("=" * 70)

        balanced_acc = results['balanced']['balanced_accuracy']
        severe_acc = results['severe']['balanced_accuracy']
        accuracy_drop = (balanced_acc - severe_acc) * 100

        print("ðŸŽ¯ ÐžÐ¡ÐÐžÐ’ÐÐ«Ð• Ð’Ð«Ð’ÐžÐ”Ð«:")
        print(f"   â€¢ Ð’Ð°ÑˆÐ¸ Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ: {balanced_acc:.1%} balanced accuracy")
        print(f"   â€¢ Ð ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ: {severe_acc:.1%} balanced accuracy")
        print(f"   â€¢ ÐŸÐ°Ð´ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸: {accuracy_drop:.1f}%")

        print(f"\nâœ… Ð’ÐÐ¨Ð˜ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« 99.3%/97% ÐÐ• ÐŸÐžÐ”ÐžÐ—Ð Ð˜Ð¢Ð•Ð›Ð¬ÐÐ«!")
        print("   ÐŸÐ Ð˜Ð§Ð˜ÐÐ«:")
        print("   â€¢ Ð˜Ð´ÐµÐ°Ð»ÑŒÐ½Ð¾ ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ")
        print("   â€¢ ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ ÑÑŠÐµÐ¼ÐºÐ¸")
        print("   â€¢ ÐšÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¿ÐµÐºÑ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ")
        print("   â€¢ Ð¡Ð¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð½Ñ‹Ð¼ Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð´Ð»Ñ Ñ‚Ð°ÐºÐ¸Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸Ð¹")

        print(f"\nâš ï¸ Ð’ÐÐ–ÐÐ«Ð• ÐŸÐ Ð•Ð”Ð£ÐŸÐ Ð•Ð–Ð”Ð•ÐÐ˜Ð¯:")
        print(f"   â€¢ Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ… Ð¾Ð¶Ð¸Ð´Ð°Ð¹Ñ‚Ðµ {severe_acc:.0%}-{severe_acc*1.1:.0%}")
        print(f"   â€¢ ÐÐ• ÑÐºÑÑ‚Ñ€Ð°Ð¿Ð¾Ð»Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð½Ð° Ð¿Ð¾Ð»ÐµÐ²Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ")
        print(f"   â€¢ Ð£ÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹Ñ‚Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€Ð¸ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²")
        print(f"   â€¢ ÐŸÐ»Ð°Ð½Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸ÑŽ Ð½Ð° Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…")

        print(f"\nðŸ› ï¸ Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð˜ Ð”Ð›Ð¯ Ð”ÐÐ›Ð¬ÐÐ•Ð™Ð¨Ð•Ð™ Ð ÐÐ‘ÐžÐ¢Ð«:")
        print("   1. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Balanced Accuracy ÐºÐ°Ðº Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÑƒ")
        print("   2. ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐ¹Ñ‚Ðµ class_weight='balanced' Ð² Ð¼Ð¾Ð´ÐµÐ»ÑÑ…")
        print("   3. Ð¡Ð¾Ð±Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð²Ð¸Ð´Ð¾Ð²")
        print("   4. Ð’Ð½ÐµÐ´Ñ€ÑÐ¹Ñ‚Ðµ Ð°Ð½ÑÐ°Ð¼Ð±Ð»ÐµÐ²Ñ‹Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ñ ÑƒÑÑ‚Ð¾Ð¹Ñ‡Ð¸Ð²Ð¾ÑÑ‚Ð¸")
        print("   5. Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð² Ñ€Ð°Ð·Ð½Ñ‹Ñ… ÑÐµÐ·Ð¾Ð½Ð½Ñ‹Ñ… Ð¸ Ð¿Ð¾Ð³Ð¾Ð´Ð½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ…")

        print(f"\nðŸ“ Ð”Ð›Ð¯ ÐŸÐ£Ð‘Ð›Ð˜ÐšÐÐ¦Ð˜Ð˜ Ð¤ÐžÐ ÐœÐ£Ð›Ð˜Ð Ð£Ð™Ð¢Ð• Ð¢ÐÐš:")
        print('   âŒ "ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð°ÐµÑ‚ 99% Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸"')
        print('   âœ… "ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð°ÐµÑ‚ 99% Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð½Ð° ÑÐ±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ…')
        print('      Ð»Ð°Ð±Ð¾Ñ€Ð°Ñ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¸ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ…"')

    def run_complete_solution(self):
        """Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹"""

        try:
            # Ð¨Ð°Ð³ 1: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…
            imbalance_ratio = self.load_and_analyze_data()

            # Ð¨Ð°Ð³ 2: ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
            self.explain_high_results(imbalance_ratio)

            # Ð¨Ð°Ð³ 3: Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð² Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ñ… ÑƒÑÐ»Ð¾Ð²Ð¸ÑÑ…
            results = self.test_realistic_conditions()

            # Ð¨Ð°Ð³ 4: Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼
            self.provide_proper_metrics_recommendations()

            # Ð¨Ð°Ð³ 5: Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            improved_model = self.create_improved_model()

            # Ð¨Ð°Ð³ 6: Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
            self.visualize_comparison(results)

            # Ð¨Ð°Ð³ 7: Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚
            self.generate_final_report(results)

            print(f"\n" + "=" * 70)
            print("âœ… ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ Ð Ð•Ð¨Ð•ÐÐ ÐŸÐžÐ›ÐÐžÐ¡Ð¢Ð¬Ð®!")
            print("=" * 70)
            print("ðŸŽ¯ Ð—ÐÐšÐ›Ð®Ð§Ð•ÐÐ˜Ð•:")
            print("   â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ñ‹ Ð¸ Ð¾Ð±Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ñ‹")
            print("   â€¢ ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¾Ñ†ÐµÐ½ÐºÐ¸")
            print("   â€¢ Ð¡Ð¾Ð·Ð´Ð°Ð½Ñ‹ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ñ‡ÐµÑÑ‚Ð½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸")
            print("   â€¢ Ð”Ð°Ð½Ñ‹ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ")
            print("=" * 70)

            return True

        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: {e}")
            print("ðŸ’¡ Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¿Ð°Ð¿ÐºÐ° Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚ Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°")
            return False


def main():
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð¿ÑƒÑÐºÐ° Ñ€ÐµÑˆÐµÐ½Ð¸Ñ"""

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ
    solution = SuspiciousResultsSolution()

    # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ
    success = solution.run_complete_solution()

    if success:
        print(f"\nðŸŽ‰ ÐœÐ˜Ð¡Ð¡Ð˜Ð¯ Ð’Ð«ÐŸÐžÐ›ÐÐ•ÐÐ!")
        print("ðŸ“Š Ð’ÑÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² Ñ„Ð°Ð¹Ð»Ñ‹ Ð¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸")
        print("ðŸ”¬ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ñ‡ÐµÑÑ‚Ð½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹")
    else:
        print(f"\nâš ï¸ Ð’Ð¾Ð·Ð½Ð¸ÐºÐ»Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¿Ñ€Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸")
        print("ðŸ”§ ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°")


if __name__ == "__main__":
    main()
