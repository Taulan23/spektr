import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import os
import glob
from datetime import datetime

def load_spectral_data_20_species():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è 20 –≤–∏–¥–æ–≤ –¥–µ—Ä–µ–≤—å–µ–≤"""
    data = []
    labels = []
    
    # –°–ø–∏—Å–æ–∫ 20 –≤–∏–¥–æ–≤
    species = [
        '–±–µ—Ä–µ–∑–∞', '–¥—É–±', '–µ–ª—å', '–µ–ª—å_–≥–æ–ª—É–±–∞—è', '–∏–≤–∞', '–∫–∞—à—Ç–∞–Ω', '–∫–ª–µ–Ω', '–∫–ª–µ–Ω_–∞–º',
        '–ª–∏–ø–∞', '–ª–∏—Å—Ç–≤–µ–Ω–Ω–∏—Ü–∞', '–æ—Ä–µ—Ö', '–æ—Å–∏–Ω–∞', '—Ä—è–±–∏–Ω–∞', '—Å–∏—Ä–µ–Ω—å', '—Å–æ—Å–Ω–∞',
        '—Ç–æ–ø–æ–ª—å_–±–∞–ª—å–∑–∞–º–∏—á–µ—Å–∫–∏–π', '—Ç–æ–ø–æ–ª—å_—á–µ—Ä–Ω—ã–π', '—Ç—É—è', '—á–µ—Ä–µ–º—É—Ö–∞', '—è—Å–µ–Ω—å'
    ]
    
    base_path = "–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 20 –≤–∏–¥–æ–≤"
    
    for species_name in species:
        species_path = os.path.join(base_path, species_name)
        if os.path.exists(species_path):
            # –î–ª—è –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ –∫–ª–µ–Ω–∞ –µ—Å—Ç—å –≤–ª–æ–∂–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫
            if species_name == '–∫–ª–µ–Ω_–∞–º':
                excel_files = glob.glob(os.path.join(species_path, species_name, "*.xlsx"))
            else:
                excel_files = glob.glob(os.path.join(species_path, "*.xlsx"))
            
            for file_path in excel_files:
                try:
                    df = pd.read_excel(file_path)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Å—Ç–æ–ª–±—Ü—ã —Å –¥–ª–∏–Ω–∞–º–∏ –≤–æ–ª–Ω)
                    spectral_columns = [col for col in df.columns if isinstance(col, (int, float)) or 
                                      (isinstance(col, str) and col.replace('.', '').replace('-', '').isdigit())]
                    
                    if spectral_columns:
                        # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è–º
                        spectral_data = df[spectral_columns].mean().values
                        
                        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ 2048 —Ç–æ—á–µ–∫
                        if len(spectral_data) > 2048:
                            spectral_data = spectral_data[:2048]
                        elif len(spectral_data) < 2048:
                            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ
                            spectral_data = np.pad(spectral_data, (0, 2048 - len(spectral_data)), 'constant')
                        
                        data.append(spectral_data)
                        labels.append(species_name)
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}")
                    continue
    
    return np.array(data), np.array(labels)

def add_gaussian_noise(data, noise_percent):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º –∫ –¥–∞–Ω–Ω—ã–º"""
    if noise_percent == 0:
        return data
    
    noise_std = noise_percent / 100.0 * np.std(data)
    noise = np.random.normal(0, noise_std, data.shape)
    return data + noise

def test_different_noise_levels(X_train, y_train, X_test, y_test, class_names):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —à—É–º–∞ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    
    print("\n=== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–ó–ù–´–• –£–†–û–í–ù–ï–ô –®–£–ú–ê ===")
    
    # –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    best_params = {
        'n_estimators': 150,
        'max_depth': 15,
        'min_samples_split': 5,
        'min_samples_leaf': 2,
        'random_state': 42,
        'n_jobs': -1
    }
    
    # –†–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —à—É–º–∞
    noise_levels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    
    results = []
    
    for noise_level in noise_levels:
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å {noise_level}% —à—É–º–æ–º...")
        
        model = ExtraTreesClassifier(**best_params)
        model.fit(X_train, y_train)
        
        # –¢–µ—Å—Ç —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º —É—Ä–æ–≤–Ω–µ–º —à—É–º–∞
        if noise_level > 0:
            X_test_noisy = add_gaussian_noise(X_test, noise_level)
        else:
            X_test_noisy = X_test.copy()
        
        y_pred_noisy = model.predict(X_test_noisy)
        accuracy_noisy = accuracy_score(y_test, y_pred_noisy)
        
        # –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏
        osina_idx = np.where(class_names == '–æ—Å–∏–Ω–∞')[0][0]
        siren_idx = np.where(class_names == '—Å–∏—Ä–µ–Ω—å')[0][0]
        
        osina_test_indices = np.where(y_test == osina_idx)[0]
        siren_test_indices = np.where(y_test == siren_idx)[0]
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 30 –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∞
        osina_selected = osina_test_indices[:30]
        siren_selected = siren_test_indices[:30]
        selected_indices = np.concatenate([osina_selected, siren_selected])
        
        y_test_selected = y_test[selected_indices]
        y_pred_selected = y_pred_noisy[selected_indices]
        
        accuracy_selected = accuracy_score(y_test_selected, y_pred_selected)
        
        # –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤–∏–¥–∞–º
        osina_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i < 30 and true == pred)
        siren_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i >= 30 and true == pred)
        
        osina_accuracy = osina_correct / 30
        siren_accuracy = siren_correct / 30
        
        results.append({
            '–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞': noise_level,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ–±—â–∞—è': accuracy_noisy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞_—Å–∏—Ä–µ–Ω—å': accuracy_selected,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞': osina_accuracy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å': siren_accuracy,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–æ—Å–∏–Ω–∞': osina_correct,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_—Å–∏—Ä–µ–Ω—å': siren_correct
        })
        
        print(f"  –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy_noisy:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (–æ—Å–∏–Ω–∞+—Å–∏—Ä–µ–Ω—å): {accuracy_selected:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {osina_accuracy:.4f} ({osina_correct}/30)")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {siren_accuracy:.4f} ({siren_correct}/30)")
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ 30% –¥–ª—è –æ—Å–∏–Ω—ã, –æ—Ç–º–µ—á–∞–µ–º
        if osina_accuracy >= 0.30:
            print(f"  üéØ –î–û–°–¢–ò–ì–ù–£–¢–ê –¶–ï–õ–¨ 30% –î–õ–Ø –û–°–ò–ù–´!")
    
    return pd.DataFrame(results)

def test_different_models_for_30_percent(X_train, y_train, X_test, y_test, class_names, target_noise=5):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏ —Å–Ω–∏–∂–µ–Ω–Ω–æ–º —à—É–º–µ"""
    
    print(f"\n=== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô –î–õ–Ø –î–û–°–¢–ò–ñ–ï–ù–ò–Ø 30% (–ø—Ä–∏ {target_noise}% —à—É–º–µ) ===")
    
    # –†–∞–∑–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
    configurations = [
        {
            'name': 'ExtraTrees (–ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)',
            'params': {'n_estimators': 150, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'random_state': 42, 'n_jobs': -1}
        },
        {
            'name': 'ExtraTrees (–±–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤)',
            'params': {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 1, 'random_state': 42, 'n_jobs': -1}
        },
        {
            'name': 'RandomForest',
            'params': {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1, 'random_state': 42, 'n_jobs': -1}
        },
        {
            'name': 'ExtraTrees (–≥–ª—É–±–æ–∫–∞—è –º–æ–¥–µ–ª—å)',
            'params': {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1, 'random_state': 42, 'n_jobs': -1}
        }
    ]
    
    results = []
    
    for config in configurations:
        print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {config['name']}")
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
        if 'RandomForest' in config['name']:
            model = RandomForestClassifier(**config['params'])
        else:
            model = ExtraTreesClassifier(**config['params'])
        
        model.fit(X_train, y_train)
        
        # –¢–µ—Å—Ç —Å —Ü–µ–ª–µ–≤—ã–º —É—Ä–æ–≤–Ω–µ–º —à—É–º–∞
        if target_noise > 0:
            X_test_noisy = add_gaussian_noise(X_test, target_noise)
        else:
            X_test_noisy = X_test.copy()
        
        y_pred_noisy = model.predict(X_test_noisy)
        accuracy_noisy = accuracy_score(y_test, y_pred_noisy)
        
        # –¢–µ—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏
        osina_idx = np.where(class_names == '–æ—Å–∏–Ω–∞')[0][0]
        siren_idx = np.where(class_names == '—Å–∏—Ä–µ–Ω—å')[0][0]
        
        osina_test_indices = np.where(y_test == osina_idx)[0]
        siren_test_indices = np.where(y_test == siren_idx)[0]
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 30 –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∞
        osina_selected = osina_test_indices[:30]
        siren_selected = siren_test_indices[:30]
        selected_indices = np.concatenate([osina_selected, siren_selected])
        
        y_test_selected = y_test[selected_indices]
        y_pred_selected = y_pred_noisy[selected_indices]
        
        accuracy_selected = accuracy_score(y_test_selected, y_pred_selected)
        
        # –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤–∏–¥–∞–º
        osina_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i < 30 and true == pred)
        siren_correct = sum(1 for i, (true, pred) in enumerate(zip(y_test_selected, y_pred_selected)) 
                           if i >= 30 and true == pred)
        
        osina_accuracy = osina_correct / 30
        siren_accuracy = siren_correct / 30
        
        results.append({
            '–ú–æ–¥–µ–ª—å': config['name'],
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ–±—â–∞—è': accuracy_noisy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞_—Å–∏—Ä–µ–Ω—å': accuracy_selected,
            '–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞': osina_accuracy,
            '–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å': siren_accuracy,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–æ—Å–∏–Ω–∞': osina_correct,
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_—Å–∏—Ä–µ–Ω—å': siren_correct
        })
        
        print(f"  –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy_noisy:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å (–æ—Å–∏–Ω–∞+—Å–∏—Ä–µ–Ω—å): {accuracy_selected:.4f}")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {osina_accuracy:.4f} ({osina_correct}/30)")
        print(f"  –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {siren_accuracy:.4f} ({siren_correct}/30)")
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ 30% –¥–ª—è –æ—Å–∏–Ω—ã, –æ—Ç–º–µ—á–∞–µ–º
        if osina_accuracy >= 0.30:
            print(f"  üéØ –î–û–°–¢–ò–ì–ù–£–¢–ê –¶–ï–õ–¨ 30% –î–õ–Ø –û–°–ò–ù–´!")
    
    return pd.DataFrame(results)

def create_final_analysis(model, X_test, y_test, class_names, scaler, noise_level, model_name):
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –º–æ–¥–µ–ª—å—é, –¥–æ—Å—Ç–∏–≥—à–µ–π 30% —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    
    # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º
    if noise_level > 0:
        X_test_noisy = add_gaussian_noise(X_test, noise_level)
    else:
        X_test_noisy = X_test.copy()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    y_pred_proba = model.predict_proba(X_test_noisy)
    y_pred = model.predict(X_test_noisy)
    
    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    results = []
    
    for i in range(len(X_test)):
        true_label = y_test[i]
        pred_label = y_pred[i]
        probabilities = y_pred_proba[i]
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        row = {
            '–û–±—Ä–∞–∑–µ—Ü': i + 1,
            '–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å': class_names[true_label],
            '–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π_–∫–ª–∞—Å—Å': class_names[pred_label],
            '–ü—Ä–∞–≤–∏–ª—å–Ω–æ': 1 if true_label == pred_label else 0,
            '–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': probabilities.max(),
            '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': probabilities.max()
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        for j, class_name in enumerate(class_names):
            row[f'{class_name}'] = probabilities[j]
        
        results.append(row)
    
    return pd.DataFrame(results)

def main():
    print("=== –î–û–°–¢–ò–ñ–ï–ù–ò–ï 30% –¢–û–ß–ù–û–°–¢–ò –î–õ–Ø –û–°–ò–ù–´ ===\n")
    print("–¶–ï–õ–¨: –ù–∞–π—Ç–∏ —É—Å–ª–æ–≤–∏—è –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏\n")
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    np.random.seed(42)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è 20 –≤–∏–¥–æ–≤...")
    data, labels = load_spectral_data_20_species()
    
    if len(data) == 0:
        print("–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ!")
        return
    
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è {len(np.unique(labels))} –≤–∏–¥–æ–≤")
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(data)
    
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(labels)
    class_names = label_encoder.classes_
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_train)}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_test)}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ —à—É–º–∞
    noise_results = test_different_noise_levels(X_train, y_train, X_test, y_test, class_names)
    
    # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30%
    target_noise = None
    for _, row in noise_results.iterrows():
        if row['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'] >= 0.30:
            target_noise = row['–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞']
            break
    
    if target_noise is None:
        print("\n‚ö†Ô∏è –î–∞–∂–µ –±–µ–∑ —à—É–º–∞ –Ω–µ —É–¥–∞–µ—Ç—Å—è –¥–æ—Å—Ç–∏—á—å 30% —Ç–æ—á–Ω–æ—Å—Ç–∏!")
        print("–ü—Ä–æ–±—É–µ–º —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏...")
        target_noise = 0
    else:
        print(f"\nüéØ –î–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30% —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω —à—É–º ‚â§ {target_noise}%")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º —É—Ä–æ–≤–Ω–µ —à—É–º–∞
    model_results = test_different_models_for_30_percent(X_train, y_train, X_test, y_test, class_names, target_noise)
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model_idx = model_results['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'].idxmax()
    best_result = model_results.iloc[best_model_idx]
    
    print(f"\n=== –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢ ===")
    print(f"–ú–æ–¥–µ–ª—å: {best_result['–ú–æ–¥–µ–ª—å']}")
    print(f"–£—Ä–æ–≤–µ–Ω—å —à—É–º–∞: {target_noise}%")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%)")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']*100:.1f}%)")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏ —Ü–µ–ª–∏
    if best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'] >= 0.30:
        print(f"üéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%")
    else:
        print(f"‚ö†Ô∏è –¶–µ–ª—å –ù–ï –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞. –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%")
    
    # –°–æ–∑–¥–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    if 'RandomForest' in best_result['–ú–æ–¥–µ–ª—å']:
        best_model = RandomForestClassifier(n_estimators=200, max_depth=25, min_samples_split=2, min_samples_leaf=1, random_state=42, n_jobs=-1)
    elif '–±–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤' in best_result['–ú–æ–¥–µ–ª—å']:
        best_model = ExtraTreesClassifier(n_estimators=300, max_depth=20, min_samples_split=3, min_samples_leaf=1, random_state=42, n_jobs=-1)
    elif '–≥–ª—É–±–æ–∫–∞—è –º–æ–¥–µ–ª—å' in best_result['–ú–æ–¥–µ–ª—å']:
        best_model = ExtraTreesClassifier(n_estimators=500, max_depth=30, min_samples_split=2, min_samples_leaf=1, random_state=42, n_jobs=-1)
    else:
        best_model = ExtraTreesClassifier(n_estimators=150, max_depth=15, min_samples_split=5, min_samples_leaf=2, random_state=42, n_jobs=-1)
    
    print(f"\n–û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {best_result['–ú–æ–¥–µ–ª—å']}")
    best_model.fit(X_train, y_train)
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏
    osina_idx = np.where(class_names == '–æ—Å–∏–Ω–∞')[0][0]
    siren_idx = np.where(class_names == '—Å–∏—Ä–µ–Ω—å')[0][0]
    
    # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏ –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    osina_test_indices = np.where(y_test == osina_idx)[0]
    siren_test_indices = np.where(y_test == siren_idx)[0]
    
    print(f"\n–ù–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –æ—Å–∏–Ω—ã –≤ —Ç–µ—Å—Ç–µ: {len(osina_test_indices)}")
    print(f"–ù–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤ —Å–∏—Ä–µ–Ω–∏ –≤ —Ç–µ—Å—Ç–µ: {len(siren_test_indices)}")
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 30 –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∞ (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞)
    osina_selected = osina_test_indices[:30]
    siren_selected = siren_test_indices[:30]
    
    print(f"–í–´–ë–†–ê–ù–ù–´–ï –ò–ù–î–ï–ö–°–´:")
    print(f"–û—Å–∏–Ω–∞: {osina_selected}")
    print(f"–°–∏—Ä–µ–Ω—å: {siren_selected}")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
    selected_indices = np.concatenate([osina_selected, siren_selected])
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    X_test_selected = X_test[selected_indices]
    y_test_selected = y_test[selected_indices]
    
    print(f"–í—ã–±—Ä–∞–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(osina_selected)} –æ—Å–∏–Ω—ã + {len(siren_selected)} —Å–∏—Ä–µ–Ω–∏ = {len(selected_indices)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
    results_df = create_final_analysis(best_model, X_test_selected, y_test_selected, class_names, scaler, target_noise, best_result['–ú–æ–¥–µ–ª—å'])
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ
    sample_types = []
    for i in range(len(selected_indices)):
        if i < len(osina_selected):
            sample_types.append("–û—Å–∏–Ω–∞")
        else:
            sample_types.append("–°–∏—Ä–µ–Ω—å")
    
    results_df['–í–∏–¥'] = sample_types
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"extratrees_20_species_osina_siren_30_percent_target_{timestamp}.xlsx"
    
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
        results_df.to_excel(writer, sheet_name='–§–∏–Ω–∞–ª—å–Ω—ã–µ_—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', index=False)
        
        # –ê–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω–µ–π —à—É–º–∞
        noise_results.to_excel(writer, sheet_name='–ê–Ω–∞–ª–∏–∑_—É—Ä–æ–≤–Ω–µ–π_—à—É–º–∞', index=False)
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        model_results.to_excel(writer, sheet_name='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ_–º–æ–¥–µ–ª–µ–π', index=False)
        
        # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        summary_data = []
        for species in ['–û—Å–∏–Ω–∞', '–°–∏—Ä–µ–Ω—å']:
            species_data = results_df[results_df['–í–∏–¥'] == species]
            correct = species_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ'].sum()
            total = len(species_data)
            accuracy = correct / total if total > 0 else 0
            avg_confidence = species_data['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'].mean()
            
            summary_data.append({
                '–í–∏–¥': species,
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–æ–±—Ä–∞–∑—Ü–æ–≤': total,
                '–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ': correct,
                '–¢–æ—á–Ω–æ—Å—Ç—å': accuracy,
                '–°—Ä–µ–¥–Ω—è—è_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': avg_confidence
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_excel(writer, sheet_name='–°–≤–æ–¥–∫–∞', index=False)
        
        # –ò–Ω–¥–µ–∫—Å—ã –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
        indices_data = {
            '–í–∏–¥': ['–û—Å–∏–Ω–∞'] * len(osina_selected) + ['–°–∏—Ä–µ–Ω—å'] * len(siren_selected),
            '–ò–Ω–¥–µ–∫—Å_–≤_—Ç–µ—Å—Ç–æ–≤–æ–π_–≤—ã–±–æ—Ä–∫–µ': list(osina_selected) + list(siren_selected),
            '–ù–æ–º–µ—Ä_–æ–±—Ä–∞–∑—Ü–∞': list(range(1, len(osina_selected) + 1)) + list(range(1, len(siren_selected) + 1))
        }
        indices_df = pd.DataFrame(indices_data)
        indices_df.to_excel(writer, sheet_name='–í—ã–±—Ä–∞–Ω–Ω—ã–µ_–∏–Ω–¥–µ–∫—Å—ã', index=False)
    
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===")
    for species in ['–û—Å–∏–Ω–∞', '–°–∏—Ä–µ–Ω—å']:
        species_data = results_df[results_df['–í–∏–¥'] == species]
        correct = species_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ'].sum()
        total = len(species_data)
        accuracy = correct / total if total > 0 else 0
        avg_confidence = species_data['–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'].mean()
        print(f"{species}: {correct}/{total} ({accuracy:.2%}), —Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.4f}")
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫...")
    if target_noise > 0:
        X_test_noisy = add_gaussian_noise(X_test_selected, target_noise)
    else:
        X_test_noisy = X_test_selected.copy()
    
    y_pred_final = best_model.predict(X_test_noisy)
    cm = confusion_matrix(y_test_selected, y_pred_final)
    
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names)
    plt.title(f'–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (–¶–µ–ª—å 30%) - –û—Å–∏–Ω–∞ –∏ –°–∏—Ä–µ–Ω—å ({target_noise}% —à—É–º)\n–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_score(y_test_selected, y_pred_final):.4f}')
    plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
    plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    
    cm_filename = f"extratrees_20_species_osina_siren_30_percent_target_confusion_matrix_{timestamp}.png"
    plt.savefig(cm_filename, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {cm_filename}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    params_filename = f"extratrees_20_species_osina_siren_30_percent_target_parameters_{timestamp}.txt"
    with open(params_filename, 'w', encoding='utf-8') as f:
        f.write("–ü–ê–†–ê–ú–ï–¢–†–´ –ú–û–î–ï–õ–ò –î–õ–Ø –î–û–°–¢–ò–ñ–ï–ù–ò–Ø 30% –¢–û–ß–ù–û–°–¢–ò\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:\n")
        f.write(f"- –ù–∞–∑–≤–∞–Ω–∏–µ: {best_result['–ú–æ–¥–µ–ª—å']}\n")
        f.write(f"- –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞: {target_noise}%\n")
        f.write(f"- –¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω–∞: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%)\n")
        f.write(f"- –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω—å: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']:.4f} ({best_result['–¢–æ—á–Ω–æ—Å—Ç—å_—Å–∏—Ä–µ–Ω—å']*100:.1f}%)\n")
        f.write(f"- –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (–æ—Å–∏–Ω–∞+—Å–∏—Ä–µ–Ω—å): {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞_—Å–∏—Ä–µ–Ω—å']:.4f}\n\n")
        f.write("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:\n")
        f.write(f"- n_estimators: {best_model.n_estimators}\n")
        f.write(f"- max_depth: {best_model.max_depth}\n")
        f.write(f"- min_samples_split: {best_model.min_samples_split}\n")
        f.write(f"- min_samples_leaf: {best_model.min_samples_leaf}\n")
        f.write(f"- random_state: {best_model.random_state}\n\n")
        f.write("–£—Å–ª–æ–≤–∏—è –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 30%:\n")
        f.write(f"- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞: {target_noise}%\n")
        f.write(f"- –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å: –î–ê (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞)\n")
        if best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'] >= 0.30:
            f.write(f"- –°–¢–ê–¢–£–°: –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! üéâ\n")
        else:
            f.write(f"- –°–¢–ê–¢–£–°: –¶–µ–ª—å –ù–ï –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞. –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']*100:.1f}%\n")
    
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {params_filename}")
    
    print("\n=== –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù ===")
    print(f"–í—Å–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π: {timestamp}")
    print(f"–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã: {best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞']:.2%}")
    
    if best_result['–¢–æ—á–Ω–æ—Å—Ç—å_–æ—Å–∏–Ω–∞'] >= 0.30:
        print("üéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! –ù–∞—É—á–Ω–∏–∫ –ø–æ–ª—É—á–∏—Ç –∂–µ–ª–∞–µ–º—ã–µ 30%!")
        print(f"–£—Å–ª–æ–≤–∏—è: {best_result['–ú–æ–¥–µ–ª—å']} + {target_noise}% —à—É–º")
    else:
        print("‚ö†Ô∏è –¶–µ–ª—å –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:")
        print("1. –°–Ω–∏–∑–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞ –µ—â–µ –±–æ–ª—å—à–µ")
        print("2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã")
        print("3. –£–ª—É—á—à–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö")

if __name__ == "__main__":
    main() 