"""
–¢–ï–°–¢: –ö–ê–ö –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–û–°–¢–¨ –í–õ–ò–Ø–ï–¢ –ù–ê –í–ê–®–ò –†–ï–ó–£–õ–¨–¢–ê–¢–´
======================================================

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –±–µ—Ä–µ—Ç –≤–∞—à–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É,
—á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∞–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.
"""

import os
import glob
import numpy as np
import pandas as pd
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, balanced_accuracy_score
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

def load_20_species_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ 20 –≤–∏–¥–æ–≤ –¥–µ—Ä–µ–≤—å–µ–≤"""
    spring_folder = "–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 20 –≤–∏–¥–æ–≤"
    
    if not os.path.exists(spring_folder):
        print(f"‚ùå –ü–∞–ø–∫–∞ {spring_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return [], [], []
    
    all_spectra = []
    all_labels = []
    species_counts = {}
    
    print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö 20 –≤–∏–¥–æ–≤...")
    
    all_folders = [f for f in os.listdir(spring_folder) 
                   if os.path.isdir(os.path.join(spring_folder, f))]
    all_folders.sort()
    
    for species in all_folders:
        folder_path = os.path.join(spring_folder, species)
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –∫–ª–µ–Ω_–∞–º
        if species == "–∫–ª–µ–Ω_–∞–º":
            subfolder_path = os.path.join(folder_path, species)
            if os.path.exists(subfolder_path):
                folder_path = subfolder_path
        
        files = glob.glob(os.path.join(folder_path, "*.xlsx"))
        
        species_spectra = []
        for file_path in files:
            try:
                df = pd.read_excel(file_path)
                if df.shape[1] >= 2:
                    spectrum = df.iloc[:, 1].values
                    spectrum = spectrum[~np.isnan(spectrum)]
                    if len(spectrum) > 100:
                        species_spectra.append(spectrum)
            except:
                continue
        
        if species_spectra:
            all_spectra.extend(species_spectra)
            all_labels.extend([species] * len(species_spectra))
            species_counts[species] = len(species_spectra)
            print(f"   üå≥ {species}: {len(species_spectra)} —Å–ø–µ–∫—Ç—Ä–æ–≤")
    
    return all_spectra, all_labels, list(species_counts.keys())

def preprocess_spectra(all_spectra, all_labels):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–µ–∫—Ç—Ä—ã"""
    min_length = min(len(spectrum) for spectrum in all_spectra)
    
    X = np.array([spectrum[:min_length] for spectrum in all_spectra])
    
    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(all_labels)
    
    return X, y, label_encoder, min_length

def create_imbalanced_datasets(X, y, species_names):
    """–°–æ–∑–¥–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    scenarios = {}
    
    # 1. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    scenarios['–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (–æ—Ä–∏–≥–∏–Ω–∞–ª)'] = (X, y)
    
    # 2. –õ–µ–≥–∫–∏–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (—É–±–∏—Ä–∞–µ–º 50% –∏–∑ –ø–æ–ª–æ–≤–∏–Ω—ã –∫–ª–∞—Å—Å–æ–≤)
    imbalanced_indices = []
    for class_idx in range(len(species_names)):
        class_mask = (y == class_idx)
        class_indices = np.where(class_mask)[0]
        
        if class_idx < 10:  # –ü–µ—Ä–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ - –º–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö
            selected = np.random.choice(class_indices, size=len(class_indices)//2, replace=False)
        else:  # –í—Ç–æ—Ä–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ - –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            selected = class_indices
        
        imbalanced_indices.extend(selected)
    
    imbalanced_indices = np.array(imbalanced_indices)
    X_imb_light = X[imbalanced_indices]
    y_imb_light = y[imbalanced_indices]
    scenarios['–õ–µ–≥–∫–∏–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (2:1)'] = (X_imb_light, y_imb_light)
    
    # 3. –°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
    # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ª–µ—Å—É
    target_proportions = [0.20, 0.15, 0.12, 0.10, 0.08, 0.07, 0.06, 0.05, 0.04, 0.04,
                         0.03, 0.02, 0.02, 0.01, 0.01, 0.01, 0.005, 0.005, 0.003, 0.002]
    
    realistic_indices = []
    total_samples = len(X)
    
    for class_idx in range(len(species_names)):
        class_mask = (y == class_idx)
        class_indices = np.where(class_mask)[0]
        
        target_count = int(total_samples * target_proportions[class_idx])
        target_count = min(target_count, len(class_indices))  # –ù–µ –±–æ–ª—å—à–µ —á–µ–º –µ—Å—Ç—å
        target_count = max(target_count, 2)  # –ú–∏–Ω–∏–º—É–º 2 –æ–±—Ä–∞–∑—Ü–∞
        
        if target_count > 0:
            selected = np.random.choice(class_indices, size=target_count, replace=False)
            realistic_indices.extend(selected)
    
    realistic_indices = np.array(realistic_indices)
    X_realistic = X[realistic_indices]
    y_realistic = y[realistic_indices]
    scenarios['–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å'] = (X_realistic, y_realistic)
    
    return scenarios

def test_scenarios(scenarios, species_names):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
    
    results = {}
    
    print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –†–ê–ó–õ–ò–ß–ù–´–• –°–¶–ï–ù–ê–†–ò–ï–í –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–û–°–¢–ò")
    print("="*70)
    
    for scenario_name, (X, y) in scenarios.items():
        print(f"\nüìä –°—Ü–µ–Ω–∞—Ä–∏–π: {scenario_name}")
        print("-" * 50)
        
        # –ü–æ–¥—Å—á–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
        unique, counts = np.unique(y, return_counts=True)
        min_count = np.min(counts)
        max_count = np.max(counts)
        imbalance_ratio = max_count / min_count
        
        print(f"   üìà –û–±—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(X)}")
        print(f"   üìà –î–∏—Å–±–∞–ª–∞–Ω—Å: {imbalance_ratio:.1f}:1")
        print(f"   üìà –ú–∏–Ω/–ú–∞–∫—Å –æ–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ –∫–ª–∞—Å—Å: {min_count}/{max_count}")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
        except ValueError:
            # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = ExtraTreesClassifier(n_estimators=200, random_state=42)
        model.fit(X_train_scaled, y_train)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        y_pred = model.predict(X_test_scaled)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(y_test, y_pred)
        balanced_acc = balanced_accuracy_score(y_test, y_pred)
        
        print(f"   üéØ Accuracy: {accuracy:.3f}")
        print(f"   üéØ Balanced Accuracy: {balanced_acc:.3f}")
        print(f"   üìâ –ü–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏: {((0.97 - accuracy) * 100):.1f}%")
        
        results[scenario_name] = {
            'accuracy': accuracy,
            'balanced_accuracy': balanced_acc,
            'imbalance_ratio': imbalance_ratio,
            'total_samples': len(X),
            'min_class_count': min_count,
            'max_class_count': max_count
        }
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
        if '–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π' in scenario_name:
            print("\n   üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º (–ø–µ—Ä–≤—ã–µ 10):")
            report = classification_report(y_test, y_pred, target_names=species_names, output_dict=True)
            for i, species in enumerate(species_names[:10]):
                if str(i) in report:
                    precision = report[str(i)]['precision']
                    recall = report[str(i)]['recall']
                    f1 = report[str(i)]['f1-score']
                    print(f"     {species:<20}: P={precision:.2f}, R={recall:.2f}, F1={f1:.2f}")
    
    return results

def create_comparison_visualization(results):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    scenarios = list(results.keys())
    accuracies = [results[s]['accuracy'] for s in scenarios]
    balanced_accs = [results[s]['balanced_accuracy'] for s in scenarios]
    imbalance_ratios = [results[s]['imbalance_ratio'] for s in scenarios]
    
    # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Accuracy vs Balanced Accuracy
    x = np.arange(len(scenarios))
    width = 0.35
    
    axes[0,0].bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='lightblue')
    axes[0,0].bar(x + width/2, balanced_accs, width, label='Balanced Accuracy', alpha=0.8, color='orange')
    axes[0,0].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
    axes[0,0].set_title('Accuracy vs Balanced Accuracy')
    axes[0,0].set_xticks(x)
    axes[0,0].set_xticklabels(scenarios, rotation=45, ha='right')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)
    axes[0,0].set_ylim(0, 1)
    
    # 2. –í–ª–∏—è–Ω–∏–µ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å
    axes[0,1].scatter(imbalance_ratios, accuracies, s=100, alpha=0.7, color='red')
    for i, scenario in enumerate(scenarios):
        axes[0,1].annotate(scenario.split()[0], (imbalance_ratios[i], accuracies[i]), 
                          xytext=(5, 5), textcoords='offset points', fontsize=10)
    axes[0,1].set_xscale('log')
    axes[0,1].set_xlabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ (log scale)')
    axes[0,1].set_ylabel('Accuracy')
    axes[0,1].set_title('–í–ª–∏—è–Ω–∏–µ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å')
    axes[0,1].grid(True, alpha=0.3)
    
    # 3. –ü–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
    original_acc = results['–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (–æ—Ä–∏–≥–∏–Ω–∞–ª)']['accuracy']
    accuracy_losses = [(original_acc - acc) * 100 for acc in accuracies]
    
    colors = ['green', 'yellow', 'red']
    axes[1,0].bar(scenarios, accuracy_losses, color=colors, alpha=0.7)
    axes[1,0].set_ylabel('–ü–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏ (%)')
    axes[1,0].set_title('–ü–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö')
    axes[1,0].tick_params(axis='x', rotation=45)
    axes[1,0].grid(True, alpha=0.3)
    
    # 4. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –∫–∞–∂–¥–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏
    total_samples = [results[s]['total_samples'] for s in scenarios]
    axes[1,1].bar(scenarios, total_samples, alpha=0.7, color='purple')
    axes[1,1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤')
    axes[1,1].set_title('–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ –∫–∞–∂–¥–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏')
    axes[1,1].tick_params(axis='x', rotation=45)
    axes[1,1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('imbalanced_reality_test.png', dpi=300, bbox_inches='tight')
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: imbalanced_reality_test.png")
    
    return fig

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –¢–ï–°–¢ –í–õ–ò–Ø–ù–ò–Ø –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–û–°–¢–ò –ù–ê –í–ê–®–ò –î–ê–ù–ù–´–ï")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    spectra, labels, species_names = load_20_species_data()
    
    if not spectra:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ!")
        return
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(spectra)} —Å–ø–µ–∫—Ç—Ä–æ–≤, {len(species_names)} –≤–∏–¥–æ–≤")
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    X, y, label_encoder, min_length = preprocess_spectra(spectra, labels)
    print(f"üìä –§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    scenarios = create_imbalanced_datasets(X, y, species_names)
    print(f"üé≠ –°–æ–∑–¥–∞–Ω–æ {len(scenarios)} —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
    results = test_scenarios(scenarios, species_names)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    create_comparison_visualization(results)
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ
    print("\n" + "="*60)
    print("üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:")
    original_acc = results['–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (–æ—Ä–∏–≥–∏–Ω–∞–ª)']['accuracy']
    realistic_acc = results['–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å']['accuracy']
    loss = (original_acc - realistic_acc) * 100
    
    print(f"   üìä –í–∞—à–∏ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {original_acc:.1%}")
    print(f"   üåç –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å: {realistic_acc:.1%}")
    print(f"   üìâ –ü–æ—Ç–µ—Ä—è —Ç–æ—á–Ω–æ—Å—Ç–∏: {loss:.1f}%")
    print("\n   ‚úÖ –í–∞—à–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ö–û–†–†–ï–ö–¢–ù–´ –¥–ª—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π!")
    print("   ‚ö†Ô∏è  –í —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö –æ–∂–∏–¥–∞–π—Ç–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è.")
    print("="*60)

if __name__ == "__main__":
    main() 