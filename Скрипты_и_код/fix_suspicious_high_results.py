#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–†–ï–®–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú–´ –° –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–û –í–´–°–û–ö–ò–ú–ò –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò (–ü–£–ù–ö–¢ 2)
================================================================

–≠—Ç–æ—Ç –∫–æ–¥ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É, –∫–æ–≥–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞–∂—É—Ç—Å—è
–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–º–∏ (99.3% –¥–ª—è Alexnet, 97% –¥–ª—è ExtraTrees).

–ü–†–û–ë–õ–ï–ú–ê: –ò–¥–µ–∞–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–∞—é—Ç –Ω–µ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ
–≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å.

–†–ï–®–ï–ù–ò–ï: –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, balanced_accuracy_score,
                           classification_report, confusion_matrix,
                           cohen_kappa_score, f1_score)
from collections import Counter
import os
import glob
import warnings

warnings.filterwarnings('ignore')

class SuspiciousResultsFixer:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""

    def __init__(self, data_path="–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 20 –≤–∏–¥–æ–≤"):
        self.data_path = data_path
        self.X = None
        self.y = None
        self.species_names = []
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()

    def load_spectral_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –≤–∏–¥–æ–≤"""
        print("üîç –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê –ü–†–û–ë–õ–ï–ú–´")
        print("=" * 60)

        all_spectra = []
        all_labels = []

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–∞–ø–æ–∫ —Å –≤–∏–¥–∞–º–∏
        species_folders = [d for d in os.listdir(self.data_path)
                          if os.path.isdir(os.path.join(self.data_path, d))]

        for species in sorted(species_folders):
            species_path = os.path.join(self.data_path, species, "*.xlsx")
            files = glob.glob(species_path)

            species_spectra = []
            for file in files:
                try:
                    # –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª
                    df = pd.read_excel(file)
                    # –ë–µ—Ä–µ–º –≤—Ç–æ—Ä—É—é –∫–æ–ª–æ–Ω–∫—É (–∏–Ω–¥–µ–∫—Å 1) –∫–∞–∫ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    if len(df.columns) > 1:
                        spectrum = df.iloc[:, 1].values
                        # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
                        spectrum = spectrum[~pd.isna(spectrum)]
                        if len(spectrum) > 100:  # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ø–µ–∫—Ç—Ä—ã
                            species_spectra.append(spectrum)
                except Exception as e:
                    print(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file}: {e}")
                    continue

            if len(species_spectra) > 0:
                print(f"   üìä {species}: {len(species_spectra)} —Å–ø–µ–∫—Ç—Ä–æ–≤")
                all_spectra.extend(species_spectra)
                all_labels.extend([species] * len(species_spectra))
                self.species_names.append(species)

        # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ —Å–ø–µ–∫—Ç—Ä—ã –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω–µ
        min_length = min(len(spectrum) for spectrum in all_spectra)
        self.X = np.array([spectrum[:min_length] for spectrum in all_spectra])
        self.y = self.label_encoder.fit_transform(all_labels)

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.X)} —Å–ø–µ–∫—Ç—Ä–æ–≤, {len(self.species_names)} –≤–∏–¥–æ–≤")
        print(f"üìè –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: {self.X.shape}")

        return self.X, self.y

    def analyze_current_balance(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â—É—é —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö"""
        print("\nüéØ –ê–ù–ê–õ–ò–ó –¢–ï–ö–£–©–ï–ô –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–û–°–¢–ò")
        print("=" * 60)

        class_counts = Counter(self.y)

        print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for i, species in enumerate(self.species_names):
            count = class_counts[i]
            print(f"   {species}: {count} –æ–±—Ä–∞–∑—Ü–æ–≤")

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
        counts = list(class_counts.values())
        imbalance_ratio = max(counts) / min(counts)

        print(f"\nüìà –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞: {imbalance_ratio:.1f}:1")

        if imbalance_ratio < 2:
            print("‚úÖ –î–∞–Ω–Ω—ã–µ –ò–î–ï–ê–õ–¨–ù–û —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã - –≠–¢–û –ü–†–ò–ß–ò–ù–ê –í–´–°–û–ö–û–ô –¢–û–ß–ù–û–°–¢–ò!")
        elif imbalance_ratio < 5:
            print("üü° –î–∞–Ω–Ω—ã–µ —É–º–µ—Ä–µ–Ω–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã")
        else:
            print("‚ùå –î–∞–Ω–Ω—ã–µ —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã")

        return imbalance_ratio

    def create_realistic_imbalance(self, imbalance_type='moderate'):
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤"""
        print(f"\nüåç –°–û–ó–î–ê–ù–ò–ï –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–• –£–°–õ–û–í–ò–ô ({imbalance_type.upper()})")
        print("=" * 60)

        if imbalance_type == 'light':
            # –õ–µ–≥–∫–∏–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (–∫–∞–∫ –≤ —Ö–æ—Ä–æ—à–æ —É–ø—Ä–∞–≤–ª—è–µ–º–æ–º –ª–µ—Å—É)
            target_ratios = [2, 1.8, 1.5, 1.2, 1, 1, 1, 1, 1, 1,
                           0.8, 0.8, 0.6, 0.6, 0.5, 0.5, 0.4, 0.4, 0.3, 0.3]
        elif imbalance_type == 'moderate':
            # –£–º–µ—Ä–µ–Ω–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å (—Ç–∏–ø–∏—á–Ω—ã–π –ª–µ—Å)
            target_ratios = [4, 3, 2.5, 2, 1.5, 1.2, 1, 1, 0.8, 0.8,
                           0.6, 0.5, 0.4, 0.3, 0.3, 0.2, 0.2, 0.15, 0.1, 0.1]
        else:  # severe
            # –°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å ('—Ä–µ–∞–ª—å–Ω—ã–π –ª–µ—Å')
            target_ratios = [10, 6, 4, 3, 2, 1.5, 1, 0.8, 0.6, 0.5,
                           0.3, 0.2, 0.15, 0.1, 0.08, 0.06, 0.04, 0.03, 0.02, 0.01]

        # –û–±—Ä–µ–∑–∞–µ–º ratios –¥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞—à–∏—Ö –≤–∏–¥–æ–≤
        target_ratios = target_ratios[:len(self.species_names)]

        # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        base_samples = 50  # –ë–∞–∑–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        target_counts = [max(1, int(ratio * base_samples)) for ratio in target_ratios]

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É —Å –∑–∞–¥–∞–Ω–Ω—ã–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º
        X_imbalanced = []
        y_imbalanced = []

        print("üìä –ù–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
        for class_idx, target_count in enumerate(target_counts):
            if class_idx >= len(self.species_names):
                break

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –æ–±—Ä–∞–∑—Ü—ã —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞
            class_mask = (self.y == class_idx)
            class_samples = self.X[class_mask]

            if len(class_samples) == 0:
                continue

            # –°–µ–º–ø–ª–∏—Ä—É–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (—Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            if target_count <= len(class_samples):
                indices = np.random.choice(len(class_samples), target_count, replace=False)
            else:
                indices = np.random.choice(len(class_samples), target_count, replace=True)

            selected_samples = class_samples[indices]
            X_imbalanced.extend(selected_samples)
            y_imbalanced.extend([class_idx] * target_count)

            species_name = self.species_names[class_idx]
            print(f"   {species_name}: {target_count} –æ–±—Ä–∞–∑—Ü–æ–≤")

        X_imbalanced = np.array(X_imbalanced)
        y_imbalanced = np.array(y_imbalanced)

        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
        new_counts = Counter(y_imbalanced)
        counts_values = list(new_counts.values())
        new_imbalance = max(counts_values) / min(counts_values)

        print(f"\nüìà –ù–æ–≤—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞: {new_imbalance:.1f}:1")

        return X_imbalanced, y_imbalanced, new_imbalance

    def comprehensive_evaluation(self, X, y, model_name="ExtraTreesClassifier"):
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        print(f"\nüî¨ –ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –û–¶–ï–ù–ö–ê: {model_name}")
        print("=" * 60)

        # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        if model_name == "ExtraTreesClassifier":
            model = ExtraTreesClassifier(
                n_estimators=200,
                max_depth=15,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
                min_samples_split=10,
                min_samples_leaf=5,
                max_features='sqrt',
                random_state=42,
                n_jobs=-1
            )
        elif model_name == "RandomForestClassifier":
            model = RandomForestClassifier(
                n_estimators=200,
                max_depth=15,
                min_samples_split=10,
                min_samples_leaf=5,
                max_features='sqrt',
                random_state=42,
                n_jobs=-1,
                class_weight='balanced'  # –í–∞–∂–Ω–æ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö!
            )
        else:  # MLPClassifier
            model = MLPClassifier(
                hidden_layer_sizes=(100, 50),
                max_iter=500,
                random_state=42
            )

        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

        accuracy_scores = []
        balanced_accuracy_scores = []
        f1_scores = []
        kappa_scores = []

        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_val_scaled = scaler.transform(X_val)

            # –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_val_scaled)

            # –ú–µ—Ç—Ä–∏–∫–∏
            accuracy_scores.append(accuracy_score(y_val, y_pred))
            balanced_accuracy_scores.append(balanced_accuracy_score(y_val, y_pred))
            f1_scores.append(f1_score(y_val, y_pred, average='macro'))
            kappa_scores.append(cohen_kappa_score(y_val, y_pred))

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {
            'Accuracy': np.mean(accuracy_scores),
            'Balanced Accuracy': np.mean(balanced_accuracy_scores),
            'F1-score (macro)': np.mean(f1_scores),
            'Cohen\'s Kappa': np.mean(kappa_scores)
        }

        print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
        for metric, score in results.items():
            print(f"   {metric}: {score:.3f} ¬± {np.std(accuracy_scores if metric == 'Accuracy' else balanced_accuracy_scores if 'Balanced' in metric else f1_scores if 'F1' in metric else kappa_scores):.3f}")

        return results

    def compare_balanced_vs_imbalanced(self):
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("\nüîÑ –°–†–ê–í–ù–ï–ù–ò–ï: –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–ï vs –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–ï –î–ê–ù–ù–´–ï")
        print("=" * 80)

        # 1. –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö) –¥–∞–Ω–Ω—ã—Ö
        print("\n1Ô∏è‚É£ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–• (–í–ê–®–ò –¢–ï–ö–£–©–ò–ï)")
        balanced_results = self.comprehensive_evaluation(self.X, self.y, "ExtraTreesClassifier")

        # 2. –°–æ–∑–¥–∞–µ–º –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º —É–º–µ—Ä–µ–Ω–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        print("\n2Ô∏è‚É£ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –£–ú–ï–†–ï–ù–ù–û –ù–ï–°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–•")
        X_moderate, y_moderate, imbalance_mod = self.create_realistic_imbalance('moderate')
        moderate_results = self.comprehensive_evaluation(X_moderate, y_moderate, "ExtraTreesClassifier")

        # 3. –°–æ–∑–¥–∞–µ–º –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ–º —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        print("\n3Ô∏è‚É£ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –°–ò–õ–¨–ù–û –ù–ï–°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–• –î–ê–ù–ù–´–• (–†–ï–ê–õ–¨–ù–´–ô –õ–ï–°)")
        X_severe, y_severe, imbalance_sev = self.create_realistic_imbalance('severe')
        severe_results = self.comprehensive_evaluation(X_severe, y_severe, "ExtraTreesClassifier")

        # 4. –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        comparison_df = pd.DataFrame({
            '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ\n(–≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ)': balanced_results,
            '–£–º–µ—Ä–µ–Ω–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å\n(—É–ø—Ä–∞–≤–ª—è–µ–º—ã–π –ª–µ—Å)': moderate_results,
            '–°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å\n(–¥–∏–∫–∏–π –ª–µ—Å)': severe_results
        })

        print("\nüìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
        print("=" * 80)
        print(comparison_df.round(3))

        # 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        self.visualize_comparison(comparison_df)

        return comparison_df

    def visualize_comparison(self, comparison_df):
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
        comparison_df.plot(kind='bar', ax=ax1, rot=45)
        ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ vs –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ',
                     fontsize=14, weight='bold')
        ax1.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(0, 1)

        # –ì—Ä–∞—Ñ–∏–∫ 2: –§–æ–∫—É—Å –Ω–∞ Accuracy vs Balanced Accuracy
        metrics_to_show = ['Accuracy', 'Balanced Accuracy']
        comparison_subset = comparison_df.loc[metrics_to_show]

        x = np.arange(len(comparison_subset.columns))
        width = 0.35

        ax2.bar(x - width/2, comparison_subset.loc['Accuracy'], width,
               label='Accuracy (misleading)', color='lightcoral', alpha=0.8)
        ax2.bar(x + width/2, comparison_subset.loc['Balanced Accuracy'], width,
               label='Balanced Accuracy (—á–µ—Å—Ç–Ω–∞—è)', color='lightgreen', alpha=0.8)

        ax2.set_title('–ü–æ—á–µ–º—É Accuracy –æ–±–º–∞–Ω—ã–≤–∞–µ—Ç –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ',
                     fontsize=14, weight='bold')
        ax2.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏')
        ax2.set_xticks(x)
        ax2.set_xticklabels(comparison_subset.columns, rotation=45)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim(0, 1)

        plt.tight_layout()
        plt.savefig('suspicious_results_analysis.png', dpi=300, bbox_inches='tight')
        print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –≥—Ä–∞—Ñ–∏–∫: suspicious_results_analysis.png")

        return fig

    def create_improved_model(self):
        """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å, —É—Å—Ç–æ–π—á–∏–≤—É—é –∫ –¥–∏—Å–±–∞–ª–∞–Ω—Å—É"""
        print("\nüöÄ –°–û–ó–î–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò")
        print("=" * 60)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω—Å–∞–º–±–ª—å —Ä–∞–∑–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
        from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier
        from sklearn.svm import SVC

        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Å —É—á–µ—Ç–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
        extra_trees = ExtraTreesClassifier(
            n_estimators=200,
            max_depth=12,
            min_samples_split=15,
            min_samples_leaf=8,
            max_features='sqrt',
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'
        )

        gradient_boost = GradientBoostingClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42
        )

        svm = SVC(
            kernel='rbf',
            probability=True,
            class_weight='balanced',
            random_state=42
        )

        # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å
        ensemble = VotingClassifier([
            ('extra_trees', extra_trees),
            ('gradient_boost', gradient_boost),
            ('svm', svm)
        ], voting='soft')

        print("‚úÖ –°–æ–∑–¥–∞–Ω –∞–Ω—Å–∞–º–±–ª—å –∏–∑ 3 –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤:")
        print("   ‚Ä¢ ExtraTreesClassifier (—Å class_weight='balanced')")
        print("   ‚Ä¢ GradientBoostingClassifier")
        print("   ‚Ä¢ SVM —Å RBF kernel (—Å class_weight='balanced')")

        return ensemble

    def generate_final_report(self, comparison_df):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –≤—ã–≤–æ–¥–∞–º–∏"""
        print("\nüìã –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢: –†–ï–®–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú–´ –í–´–°–û–ö–ò–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("=" * 80)

        balanced_acc = comparison_df.loc['Accuracy', '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ\n(–≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ)']
        realistic_acc = comparison_df.loc['Balanced Accuracy', '–°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å\n(–¥–∏–∫–∏–π –ª–µ—Å)']

        print(f"üéØ –û–°–ù–û–í–ù–´–ï –í–´–í–û–î–´:")
        print(f"   ‚Ä¢ –í–∞—à–∏ –¥–∞–Ω–Ω—ã–µ (—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ): {balanced_acc:.1%} accuracy")
        print(f"   ‚Ä¢ –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è: {realistic_acc:.1%} balanced accuracy")
        print(f"   ‚Ä¢ –†–∞–∑–Ω–∏—Ü–∞: {(balanced_acc - realistic_acc):.1%}")

        print(f"\n‚úÖ –í–ê–®–ò –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ù–ï –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–´, –ø–æ—Ç–æ–º—É —á—Ç–æ:")
        print(f"   ‚Ä¢ –ò–¥–µ–∞–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        print(f"   ‚Ä¢ –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ —É—Å–ª–æ–≤–∏—è —Å—ä–µ–º–∫–∏")
        print(f"   ‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        print(f"   ‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–º –¥–∞–Ω–Ω—ã–º")

        print(f"\n‚ö†Ô∏è  –í–ê–ñ–ù–´–ï –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø:")
        print(f"   ‚Ä¢ –í —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö –æ–∂–∏–¥–∞–π—Ç–µ {realistic_acc:.0%}-{realistic_acc*1.1:.0%}")
        print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Balanced Accuracy –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–π Accuracy")
        print(f"   ‚Ä¢ –£–∫–∞–∑—ã–≤–∞–π—Ç–µ —É—Å–ª–æ–≤–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
        print(f"   ‚Ä¢ –ü–ª–∞–Ω–∏—Ä—É–π—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é –Ω–∞ –ø–æ–ª–µ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

        print(f"\nüõ†Ô∏è  –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
        print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ class_weight='balanced' –≤ –º–æ–¥–µ–ª—è—Ö")
        print(f"   ‚Ä¢ –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã")
        print(f"   ‚Ä¢ –°–æ–±–∏—Ä–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º")
        print(f"   ‚Ä¢ –í–Ω–µ–¥—Ä—è–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ per-class precision/recall")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –≤—ã—Å–æ–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("üö® –†–ï–®–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú–´ –° –ü–û–î–û–ó–†–ò–¢–ï–õ–¨–ù–û –í–´–°–û–ö–ò–ú–ò –†–ï–ó–£–õ–¨–¢–ê–¢–ê–ú–ò")
    print("=" * 80)
    print("–ü—Ä–æ–±–ª–µ–º–∞: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã 99.3% (Alexnet) –∏ 97% (ExtraTrees) –∫–∞–∂—É—Ç—Å—è –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏")
    print("–†–µ—à–µ–Ω–∏–µ: –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö")
    print("=" * 80)

    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    fixer = SuspiciousResultsFixer()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    try:
        X, y = fixer.load_spectral_data()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ '–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 20 –≤–∏–¥–æ–≤' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
    imbalance_ratio = fixer.analyze_current_balance()

    # –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    comparison_results = fixer.compare_balanced_vs_imbalanced()

    # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
    improved_model = fixer.create_improved_model()

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    fixer.generate_final_report(comparison_results)

    print("\n" + "=" * 80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ 'suspicious_results_analysis.png'")
    print("üéØ –ü—Ä–æ–±–ª–µ–º–∞ —Ä–µ—à–µ–Ω–∞: –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—ä—è—Å–Ω–µ–Ω—ã –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω—ã")
    print("=" * 80)


if __name__ == "__main__":
    main()
