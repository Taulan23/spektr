#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–†–ê–í–ò–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–∏ - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
Extra Trees –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, 19 –≤–∏–¥–æ–≤ –¥–µ—Ä–µ–≤—å–µ–≤ (–±–µ–∑ –∫–ª–µ–Ω_–∞–º)
–û—Å–∏–Ω–∞: 93.55% —Ç–æ—á–Ω–æ—Å—Ç—å, –°–∏—Ä–µ–Ω—å: 100% —Ç–æ—á–Ω–æ—Å—Ç—å
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import os
import glob
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
np.random.seed(42)

def load_19_species_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è 19 –≤–µ—Å–µ–Ω–Ω–∏—Ö –≤–∏–¥–æ–≤ (–±–µ–∑ –∫–ª–µ–Ω_–∞–º)"""
    
    spring_folder = "–ò—Å—Ö–æ–¥–Ω—ã–µ_–¥–∞–Ω–Ω—ã–µ/–°–ø–µ–∫—Ç—Ä—ã, –≤–µ—Å–µ–Ω–Ω–∏–π –ø–µ—Ä–∏–æ–¥, 20 –≤–∏–¥–æ–≤"
    
    print("üå± –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• 19 –í–ï–°–ï–ù–ù–ò–• –í–ò–î–û–í (–ë–ï–ó –ö–õ–ï–ù_–ê–ú)...")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø–∞–ø–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–æ–¥–µ)
    all_folders = [f for f in os.listdir(spring_folder) 
                   if os.path.isdir(os.path.join(spring_folder, f)) and not f.startswith('.')]
    all_folders = sorted(all_folders)
    
    # –ò–°–ö–õ–Æ–ß–ê–ï–ú –∫–ª–µ–Ω_–∞–º –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
    if "–∫–ª–µ–Ω_–∞–º" in all_folders:
        all_folders.remove("–∫–ª–µ–Ω_–∞–º")
    
    print(f"   üìÅ –ù–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫: {len(all_folders)}")
    print(f"   üö´ –ò—Å–∫–ª—é—á–µ–Ω –∫–ª–µ–Ω_–∞–º –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º")
    
    all_data = []
    all_labels = []
    species_counts = {}
    
    for species in all_folders:
        species_folder = os.path.join(spring_folder, species)
        
        if not os.path.exists(species_folder):
            print(f"   ‚ö†Ô∏è  {species}: –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            continue
            
        files = glob.glob(os.path.join(species_folder, "*.xlsx"))
        
        print(f"   üå≥ {species}: {len(files)} —Ñ–∞–π–ª–æ–≤")
        species_counts[species] = len(files)
        
        species_data = []
        for file in files:
            try:
                df = pd.read_excel(file, header=None)
                spectrum = df.iloc[:, 1].values  # –í—Ç–æ—Ä–∞—è –∫–æ–ª–æ–Ω–∫–∞ - —Å–ø–µ–∫—Ç—Ä
                spectrum = spectrum[~pd.isna(spectrum)]  # –£–±–∏—Ä–∞–µ–º NaN
                species_data.append(spectrum)
            except Exception as e:
                print(f"     ‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ–∞–π–ª–µ {file}: {e}")
                continue
        
        if species_data:
            all_data.extend(species_data)
            all_labels.extend([species] * len(species_data))
    
    print(f"\nüìä –ò–¢–û–ì–û –ó–ê–ì–†–£–ñ–ï–ù–û:")
    for species, count in species_counts.items():
        print(f"   üå≥ {species}: {count} —Å–ø–µ–∫—Ç—Ä–æ–≤")
    
    print(f"\n‚úÖ –û–±—â–∏–π –∏—Ç–æ–≥: {len(all_data)} —Å–ø–µ–∫—Ç—Ä–æ–≤, {len(set(all_labels))} –≤–∏–¥–æ–≤")
    
    return all_data, all_labels, species_counts

def extract_features(spectra_list):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Å–ø–µ–∫—Ç—Ä–æ–≤"""
    
    print("üîß –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í...")
    
    # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
    min_length = min(len(spectrum) for spectrum in spectra_list)
    print(f"   üìè –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–ø–µ–∫—Ç—Ä–∞: {min_length}")
    
    # –û–±—Ä–µ–∑–∞–µ–º –≤—Å–µ —Å–ø–µ–∫—Ç—Ä—ã –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
    processed_spectra = []
    for spectrum in spectra_list:
        truncated = spectrum[:min_length]
        processed_spectra.append(truncated)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array
    X = np.array(processed_spectra)
    print(f"   üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
    
    return X

def add_noise(X, noise_level):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –≥–∞—É—Å—Å–æ–≤—Å–∫–∏–π —à—É–º –∫ –¥–∞–Ω–Ω—ã–º"""
    if noise_level == 0:
        return X
    noise = np.random.normal(0, noise_level, X.shape).astype(np.float32)
    return X + noise

def create_dissertation_excel_analysis(model, X_test, y_test, tree_types, noise_level=10):
    """–°–æ–∑–¥–∞–µ—Ç Excel –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    
    print(f"\nüìä –°–û–ó–î–ê–ù–ò–ï EXCEL –ê–ù–ê–õ–ò–ó–ê –î–õ–Ø –î–ò–°–°–ï–†–¢–ê–¶–ò–ò...")
    print(f"–£—Ä–æ–≤–µ–Ω—å —à—É–º–∞: {noise_level}%")
    print(f"–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –û—Å–∏–Ω–∞ ~93.55%, –°–∏—Ä–µ–Ω—å ~100%")
    
    # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –æ—Å–∏–Ω—ã –∏ —Å–∏—Ä–µ–Ω–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    osina_idx = np.where(tree_types == '–æ—Å–∏–Ω–∞')[0][0]
    sirene_idx = np.where(tree_types == '—Å–∏—Ä–µ–Ω—å')[0][0]
    
    osina_indices = np.where(y_test == osina_idx)[0]
    sirene_indices = np.where(y_test == sirene_idx)[0]
    
    print(f"   üå≥ –û—Å–∏–Ω–∞ (–∏–Ω–¥–µ–∫—Å {osina_idx}): {len(osina_indices)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"   üå∏ –°–∏—Ä–µ–Ω—å (–∏–Ω–¥–µ–∫—Å {sirene_idx}): {len(sirene_indices)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º
    X_test_noisy = add_noise(X_test, noise_level / 100.0)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_proba = model.predict_proba(X_test_noisy)
    
    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    analysis_data = []
    
    # –ê–Ω–∞–ª–∏–∑ –æ—Å–∏–Ω—ã
    for i, idx in enumerate(osina_indices):
        row_data = {
            '–ù–æ–º–µ—Ä_–æ–±—Ä–∞–∑—Ü–∞': f'–û—Å–∏–Ω–∞_{i+1:02d}',
            '–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å': '–æ—Å–∏–Ω–∞',
            '–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞': f'{noise_level}%'
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –≤–∏–¥–æ–≤
        for j, species in enumerate(tree_types):
            row_data[f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = y_pred_proba[idx, j]
        
        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        max_prob_idx = np.argmax(y_pred_proba[idx])
        max_prob = y_pred_proba[idx, max_prob_idx]
        predicted_species = tree_types[max_prob_idx]
        
        row_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'] = max_prob
        row_data['–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π_–∫–ª–∞—Å—Å'] = predicted_species
        row_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'] = predicted_species == '–æ—Å–∏–Ω–∞'
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å = 1, –æ—Å—Ç–∞–ª—å–Ω—ã–µ = 0
        for j, species in enumerate(tree_types):
            if j == max_prob_idx:
                row_data[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = 1.0
            else:
                row_data[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = 0.0
        
        analysis_data.append(row_data)
    
    # –ê–Ω–∞–ª–∏–∑ —Å–∏—Ä–µ–Ω–∏
    for i, idx in enumerate(sirene_indices):
        row_data = {
            '–ù–æ–º–µ—Ä_–æ–±—Ä–∞–∑—Ü–∞': f'–°–∏—Ä–µ–Ω—å_{i+1:02d}',
            '–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å': '—Å–∏—Ä–µ–Ω—å',
            '–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞': f'{noise_level}%'
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –≤–∏–¥–æ–≤
        for j, species in enumerate(tree_types):
            row_data[f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = y_pred_proba[idx, j]
        
        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        max_prob_idx = np.argmax(y_pred_proba[idx])
        max_prob = y_pred_proba[idx, max_prob_idx]
        predicted_species = tree_types[max_prob_idx]
        
        row_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'] = max_prob
        row_data['–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π_–∫–ª–∞—Å—Å'] = predicted_species
        row_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'] = predicted_species == '—Å–∏—Ä–µ–Ω—å'
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å = 1, –æ—Å—Ç–∞–ª—å–Ω—ã–µ = 0
        for j, species in enumerate(tree_types):
            if j == max_prob_idx:
                row_data[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = 1.0
            else:
                row_data[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = 0.0
        
        analysis_data.append(row_data)
    
    # –°–æ–∑–¥–∞–µ–º DataFrame
    df_analysis = pd.DataFrame(analysis_data)
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    osina_data = df_analysis[df_analysis['–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å'] == '–æ—Å–∏–Ω–∞']
    sirene_data = df_analysis[df_analysis['–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å'] == '—Å–∏—Ä–µ–Ω—å']
    
    # –°—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Å–∏–Ω—ã
    osina_avg = {
        '–ù–æ–º–µ—Ä_–æ–±—Ä–∞–∑—Ü–∞': '–°–†–ï–î–ù–ï–ï_–û–°–ò–ù–ê',
        '–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å': '–æ—Å–∏–Ω–∞',
        '–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞': f'{noise_level}%'
    }
    
    # –°—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–∏—Ä–µ–Ω–∏
    sirene_avg = {
        '–ù–æ–º–µ—Ä_–æ–±—Ä–∞–∑—Ü–∞': '–°–†–ï–î–ù–ï–ï_–°–ò–†–ï–ù–¨',
        '–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å': '—Å–∏—Ä–µ–Ω—å',
        '–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞': f'{noise_level}%'
    }
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    for species in tree_types:
        osina_avg[f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = osina_data[f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'].mean()
        sirene_avg[f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = sirene_data[f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'].mean()
        osina_avg[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = osina_data[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'].mean()
        sirene_avg[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'] = sirene_data[f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}'].mean()
    
    osina_avg['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'] = osina_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'].mean()
    sirene_avg['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'] = sirene_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'].mean()
    osina_avg['–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π_–∫–ª–∞—Å—Å'] = '–æ—Å–∏–Ω–∞' if osina_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean() > 0.5 else '–¥—Ä—É–≥–æ–π'
    sirene_avg['–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π_–∫–ª–∞—Å—Å'] = '—Å–∏—Ä–µ–Ω—å' if sirene_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean() > 0.5 else '–¥—Ä—É–≥–æ–π'
    osina_avg['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'] = osina_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean()
    sirene_avg['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'] = sirene_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
    df_analysis = pd.concat([
        df_analysis,
        pd.DataFrame([osina_avg]),
        pd.DataFrame([sirene_avg])
    ], ignore_index=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª–∏—Å—Ç–∞–º–∏
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f'dissertation_analysis_{timestamp}.xlsx'
    
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        # –û—Å–Ω–æ–≤–Ω–æ–π –ª–∏—Å—Ç —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
        df_analysis.to_excel(writer, sheet_name='–î–µ—Ç–∞–ª—å–Ω—ã–π_–∞–Ω–∞–ª–∏–∑', index=False)
        
        # –õ–∏—Å—Ç —Ç–æ–ª—å–∫–æ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
        prob_cols = ['–ù–æ–º–µ—Ä_–æ–±—Ä–∞–∑—Ü–∞', '–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å', '–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞'] + [f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}' for species in tree_types]
        df_analysis[prob_cols].to_excel(writer, sheet_name='–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', index=False)
        
        # –õ–∏—Å—Ç —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (1/0)
        max_prob_cols = ['–ù–æ–º–µ—Ä_–æ–±—Ä–∞–∑—Ü–∞', '–ò—Å—Ç–∏–Ω–Ω—ã–π_–∫–ª–∞—Å—Å', '–£—Ä–æ–≤–µ–Ω—å_—à—É–º–∞'] + [f'–ú–∞–∫—Å_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_{species}' for species in tree_types]
        df_analysis[max_prob_cols].to_excel(writer, sheet_name='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', index=False)
        
        # –õ–∏—Å—Ç —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats_data = {
            '–ú–µ—Ç—Ä–∏–∫–∞': [
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –æ—Å–∏–Ω—ã',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ —Å–∏—Ä–µ–Ω–∏',
                '–ü—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –æ—Å–∏–Ω—ã',
                '–ü—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ —Å–∏—Ä–µ–Ω–∏',
                '–¢–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã',
                '–¢–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω–∏',
                '–°—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã',
                '–°—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω–∏',
                '–£—Ä–æ–≤–µ–Ω—å —à—É–º–∞',
                '–ò–Ω–¥–µ–∫—Å –æ—Å–∏–Ω—ã –≤ confusion matrix',
                '–ò–Ω–¥–µ–∫—Å —Å–∏—Ä–µ–Ω–∏ –≤ confusion matrix',
                '–û–∂–∏–¥–∞–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã (–∏–∑ confusion matrix)',
                '–û–∂–∏–¥–∞–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω–∏ (–∏–∑ confusion matrix)'
            ],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                len(osina_data),
                len(sirene_data),
                osina_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].sum(),
                sirene_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].sum(),
                f"{osina_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean():.4f}",
                f"{sirene_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean():.4f}",
                f"{osina_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'].mean():.4f}",
                f"{sirene_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'].mean():.4f}",
                f"{noise_level}%",
                osina_idx,
                sirene_idx,
                "93.55%",
                "100%"
            ]
        }
        pd.DataFrame(stats_data).to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)
    
    print(f"‚úÖ Excel —Ñ–∞–π–ª –¥–ª—è –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê –î–õ–Ø –î–ò–°–°–ï–†–¢–ê–¶–ò–ò:")
    print(f"   üå≥ –û—Å–∏–Ω–∞ (–∏–Ω–¥–µ–∫—Å {osina_idx}): {len(osina_data)} –æ–±—Ä–∞–∑—Ü–æ–≤, —Ç–æ—á–Ω–æ—Å—Ç—å: {osina_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean():.4f}")
    print(f"   üå∏ –°–∏—Ä–µ–Ω—å (–∏–Ω–¥–µ–∫—Å {sirene_idx}): {len(sirene_data)} –æ–±—Ä–∞–∑—Ü–æ–≤, —Ç–æ—á–Ω–æ—Å—Ç—å: {sirene_data['–ü—Ä–∞–≤–∏–ª—å–Ω–æ_–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω'].mean():.4f}")
    print(f"   üìà –°—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Å–∏–Ω—ã: {osina_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'].mean():.4f}")
    print(f"   üìà –°—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∏—Ä–µ–Ω–∏: {sirene_data['–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è_–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'].mean():.4f}")
    print(f"   üéØ –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: –û—Å–∏–Ω–∞ ~93.55%, –°–∏—Ä–µ–Ω—å ~100%")
    
    return filename

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üöÄ –ü–†–ê–í–ò–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –î–õ–Ø –î–ò–°–°–ï–†–¢–ê–¶–ò–ò")
    print("="*70)
    print("üìã –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º:")
    print("   üå≥ –û—Å–∏–Ω–∞: 93.55% —Ç–æ—á–Ω–æ—Å—Ç—å")
    print("   üå∏ –°–∏—Ä–µ–Ω—å: 100% —Ç–æ—á–Ω–æ—Å—Ç—å")
    print("="*70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    all_data, all_labels, species_counts = load_19_species_data()
    
    if not all_data:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X = extract_features(all_data)
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
    le = LabelEncoder()
    y_encoded = le.fit_transform(all_labels)
    tree_types = le.classes_
    
    print(f"\nüìä –§–ò–ù–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï:")
    print(f"   X shape: {X.shape}")
    print(f"   y shape: {y_encoded.shape}")
    print(f"   –ö–ª–∞—Å—Å—ã: {tree_types}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö 80/20
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    print(f"\nüìä –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–•:")
    print(f"   –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"   –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print(f"\nüéØ –û–ë–£–ß–ï–ù–ò–ï EXTRA TREES –ú–û–î–ï–õ–ò...")
    
    model = ExtraTreesClassifier(
        n_estimators=1712,
        max_depth=None,
        min_samples_split=2,
        min_samples_leaf=1,
        random_state=42,
        n_jobs=-1
    )
    
    model.fit(X_train, y_train)
    
    # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —á–∏—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüìä –û–¶–ï–ù–ö–ê –ù–ê –ß–ò–°–¢–´–• –î–ê–ù–ù–´–•...")
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —á–∏—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {accuracy:.7f}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ Excel –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏–∏
    excel_file = create_dissertation_excel_analysis(model, X_test, y_test, tree_types, noise_level=10)
    
    print(f"\nüéâ –ê–ù–ê–õ–ò–ó –î–õ–Ø –î–ò–°–°–ï–†–¢–ê–¶–ò–ò –ì–û–¢–û–í!")
    print(f"üìÅ Excel —Ñ–∞–π–ª: {excel_file}")
    print(f"‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º confusion matrix")

if __name__ == "__main__":
    main() 